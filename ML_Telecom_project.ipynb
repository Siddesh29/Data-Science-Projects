{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66f44a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb762be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e823730c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>...</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7590-VHVEG</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5575-GNVDE</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>34</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.5</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3668-QPYBK</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7795-CFOCW</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>45</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9237-HQITU</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
       "0  7590-VHVEG  Female              0     Yes         No       1           No   \n",
       "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
       "2  3668-QPYBK    Male              0      No         No       2          Yes   \n",
       "3  7795-CFOCW    Male              0      No         No      45           No   \n",
       "4  9237-HQITU  Female              0      No         No       2          Yes   \n",
       "\n",
       "      MultipleLines InternetService OnlineSecurity  ... DeviceProtection  \\\n",
       "0  No phone service             DSL             No  ...               No   \n",
       "1                No             DSL            Yes  ...              Yes   \n",
       "2                No             DSL            Yes  ...               No   \n",
       "3  No phone service             DSL            Yes  ...              Yes   \n",
       "4                No     Fiber optic             No  ...               No   \n",
       "\n",
       "  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling  \\\n",
       "0          No          No              No  Month-to-month              Yes   \n",
       "1          No          No              No        One year               No   \n",
       "2          No          No              No  Month-to-month              Yes   \n",
       "3         Yes          No              No        One year               No   \n",
       "4          No          No              No  Month-to-month              Yes   \n",
       "\n",
       "               PaymentMethod MonthlyCharges  TotalCharges Churn  \n",
       "0           Electronic check          29.85         29.85    No  \n",
       "1               Mailed check          56.95        1889.5    No  \n",
       "2               Mailed check          53.85        108.15   Yes  \n",
       "3  Bank transfer (automatic)          42.30       1840.75    No  \n",
       "4           Electronic check          70.70        151.65   Yes  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the dataset\n",
    "df=pd.read_csv('telecom_churn (1).csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d6e1b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7043, 21)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check size of dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e8dd38e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customerID          0\n",
       "gender              0\n",
       "SeniorCitizen       0\n",
       "Partner             0\n",
       "Dependents          0\n",
       "tenure              0\n",
       "PhoneService        0\n",
       "MultipleLines       0\n",
       "InternetService     0\n",
       "OnlineSecurity      0\n",
       "OnlineBackup        0\n",
       "DeviceProtection    0\n",
       "TechSupport         0\n",
       "StreamingTV         0\n",
       "StreamingMovies     0\n",
       "Contract            0\n",
       "PaperlessBilling    0\n",
       "PaymentMethod       0\n",
       "MonthlyCharges      0\n",
       "TotalCharges        0\n",
       "Churn               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "466978d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customerID           object\n",
       "gender               object\n",
       "SeniorCitizen         int64\n",
       "Partner              object\n",
       "Dependents           object\n",
       "tenure                int64\n",
       "PhoneService         object\n",
       "MultipleLines        object\n",
       "InternetService      object\n",
       "OnlineSecurity       object\n",
       "OnlineBackup         object\n",
       "DeviceProtection     object\n",
       "TechSupport          object\n",
       "StreamingTV          object\n",
       "StreamingMovies      object\n",
       "Contract             object\n",
       "PaperlessBilling     object\n",
       "PaymentMethod        object\n",
       "MonthlyCharges      float64\n",
       "TotalCharges         object\n",
       "Churn                object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cross check for null values with data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b26708c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for duplicate data\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4d3eca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>34</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.5</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>45</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
       "0  Female              0     Yes         No       1           No   \n",
       "1    Male              0      No         No      34          Yes   \n",
       "2    Male              0      No         No       2          Yes   \n",
       "3    Male              0      No         No      45           No   \n",
       "4  Female              0      No         No       2          Yes   \n",
       "\n",
       "      MultipleLines InternetService OnlineSecurity OnlineBackup  \\\n",
       "0  No phone service             DSL             No          Yes   \n",
       "1                No             DSL            Yes           No   \n",
       "2                No             DSL            Yes          Yes   \n",
       "3  No phone service             DSL            Yes           No   \n",
       "4                No     Fiber optic             No           No   \n",
       "\n",
       "  DeviceProtection TechSupport StreamingTV StreamingMovies        Contract  \\\n",
       "0               No          No          No              No  Month-to-month   \n",
       "1              Yes          No          No              No        One year   \n",
       "2               No          No          No              No  Month-to-month   \n",
       "3              Yes         Yes          No              No        One year   \n",
       "4               No          No          No              No  Month-to-month   \n",
       "\n",
       "  PaperlessBilling              PaymentMethod  MonthlyCharges TotalCharges  \\\n",
       "0              Yes           Electronic check           29.85        29.85   \n",
       "1               No               Mailed check           56.95       1889.5   \n",
       "2              Yes               Mailed check           53.85       108.15   \n",
       "3               No  Bank transfer (automatic)           42.30      1840.75   \n",
       "4              Yes           Electronic check           70.70       151.65   \n",
       "\n",
       "  Churn  \n",
       "0    No  \n",
       "1    No  \n",
       "2   Yes  \n",
       "3    No  \n",
       "4   Yes  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#first we drop the customer id column as it is not important for predicting output\n",
    "df.drop('customerID',axis=1,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e2a3f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for duplicate data after dropping customer id column\n",
    "df.duplicated().sum() # We donot delete these duplicates, as they were unique with customer id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce42e09d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender               object\n",
       "SeniorCitizen         int64\n",
       "Partner              object\n",
       "Dependents           object\n",
       "tenure                int64\n",
       "PhoneService         object\n",
       "MultipleLines        object\n",
       "InternetService      object\n",
       "OnlineSecurity       object\n",
       "OnlineBackup         object\n",
       "DeviceProtection     object\n",
       "TechSupport          object\n",
       "StreamingTV          object\n",
       "StreamingMovies      object\n",
       "Contract             object\n",
       "PaperlessBilling     object\n",
       "PaymentMethod        object\n",
       "MonthlyCharges      float64\n",
       "TotalCharges         object\n",
       "Churn                object\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Total charges columns shows object datatype, so clearly it has some unclean data\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fe5aa7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          11\n",
       "20.2      11\n",
       "19.75      9\n",
       "20.05      8\n",
       "19.9       8\n",
       "          ..\n",
       "6849.4     1\n",
       "692.35     1\n",
       "130.15     1\n",
       "3211.9     1\n",
       "6844.5     1\n",
       "Name: TotalCharges, Length: 6531, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for null values in TotalCharges column\n",
    "df['TotalCharges'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0b6d0f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Two year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>52.55</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>Two year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>20.25</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Two year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>80.85</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082</th>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>Two year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>25.75</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1340</th>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Two year</td>\n",
       "      <td>No</td>\n",
       "      <td>Credit card (automatic)</td>\n",
       "      <td>56.05</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3331</th>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>Two year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>19.85</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3826</th>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>Two year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>25.35</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4380</th>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>Two year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>20.00</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5218</th>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>One year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>19.70</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6670</th>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Two year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>73.35</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6754</th>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Two year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>61.90</td>\n",
       "      <td></td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
       "488   Female              0     Yes        Yes       0           No   \n",
       "753     Male              0      No        Yes       0          Yes   \n",
       "936   Female              0     Yes        Yes       0          Yes   \n",
       "1082    Male              0     Yes        Yes       0          Yes   \n",
       "1340  Female              0     Yes        Yes       0           No   \n",
       "3331    Male              0     Yes        Yes       0          Yes   \n",
       "3826    Male              0     Yes        Yes       0          Yes   \n",
       "4380  Female              0     Yes        Yes       0          Yes   \n",
       "5218    Male              0     Yes        Yes       0          Yes   \n",
       "6670  Female              0     Yes        Yes       0          Yes   \n",
       "6754    Male              0      No        Yes       0          Yes   \n",
       "\n",
       "         MultipleLines InternetService       OnlineSecurity  \\\n",
       "488   No phone service             DSL                  Yes   \n",
       "753                 No              No  No internet service   \n",
       "936                 No             DSL                  Yes   \n",
       "1082               Yes              No  No internet service   \n",
       "1340  No phone service             DSL                  Yes   \n",
       "3331                No              No  No internet service   \n",
       "3826               Yes              No  No internet service   \n",
       "4380                No              No  No internet service   \n",
       "5218                No              No  No internet service   \n",
       "6670               Yes             DSL                   No   \n",
       "6754               Yes             DSL                  Yes   \n",
       "\n",
       "             OnlineBackup     DeviceProtection          TechSupport  \\\n",
       "488                    No                  Yes                  Yes   \n",
       "753   No internet service  No internet service  No internet service   \n",
       "936                   Yes                  Yes                   No   \n",
       "1082  No internet service  No internet service  No internet service   \n",
       "1340                  Yes                  Yes                  Yes   \n",
       "3331  No internet service  No internet service  No internet service   \n",
       "3826  No internet service  No internet service  No internet service   \n",
       "4380  No internet service  No internet service  No internet service   \n",
       "5218  No internet service  No internet service  No internet service   \n",
       "6670                  Yes                  Yes                  Yes   \n",
       "6754                  Yes                   No                  Yes   \n",
       "\n",
       "              StreamingTV      StreamingMovies  Contract PaperlessBilling  \\\n",
       "488                   Yes                   No  Two year              Yes   \n",
       "753   No internet service  No internet service  Two year               No   \n",
       "936                   Yes                  Yes  Two year               No   \n",
       "1082  No internet service  No internet service  Two year               No   \n",
       "1340                  Yes                   No  Two year               No   \n",
       "3331  No internet service  No internet service  Two year               No   \n",
       "3826  No internet service  No internet service  Two year               No   \n",
       "4380  No internet service  No internet service  Two year               No   \n",
       "5218  No internet service  No internet service  One year              Yes   \n",
       "6670                  Yes                   No  Two year               No   \n",
       "6754                   No                   No  Two year              Yes   \n",
       "\n",
       "                  PaymentMethod  MonthlyCharges TotalCharges Churn  \n",
       "488   Bank transfer (automatic)           52.55                 No  \n",
       "753                Mailed check           20.25                 No  \n",
       "936                Mailed check           80.85                 No  \n",
       "1082               Mailed check           25.75                 No  \n",
       "1340    Credit card (automatic)           56.05                 No  \n",
       "3331               Mailed check           19.85                 No  \n",
       "3826               Mailed check           25.35                 No  \n",
       "4380               Mailed check           20.00                 No  \n",
       "5218               Mailed check           19.70                 No  \n",
       "6670               Mailed check           73.35                 No  \n",
       "6754  Bank transfer (automatic)           61.90                 No  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we see that a blank space ' ' has 11 data points, so we need to clean it\n",
    "#first we replace the blank space with null value\n",
    "df[df['TotalCharges']==' ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5bd46d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender               0\n",
       "SeniorCitizen        0\n",
       "Partner              0\n",
       "Dependents           0\n",
       "tenure               0\n",
       "PhoneService         0\n",
       "MultipleLines        0\n",
       "InternetService      0\n",
       "OnlineSecurity       0\n",
       "OnlineBackup         0\n",
       "DeviceProtection     0\n",
       "TechSupport          0\n",
       "StreamingTV          0\n",
       "StreamingMovies      0\n",
       "Contract             0\n",
       "PaperlessBilling     0\n",
       "PaymentMethod        0\n",
       "MonthlyCharges       0\n",
       "TotalCharges        11\n",
       "Churn                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace the blank space with null value in Total Cgarges column\n",
    "df['TotalCharges'].replace(' ',np.nan,inplace=True)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8449f5a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check or data type of TotalCharges column\n",
    "df['TotalCharges'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9767a552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender               object\n",
       "SeniorCitizen         int64\n",
       "Partner              object\n",
       "Dependents           object\n",
       "tenure                int64\n",
       "PhoneService         object\n",
       "MultipleLines        object\n",
       "InternetService      object\n",
       "OnlineSecurity       object\n",
       "OnlineBackup         object\n",
       "DeviceProtection     object\n",
       "TechSupport          object\n",
       "StreamingTV          object\n",
       "StreamingMovies      object\n",
       "Contract             object\n",
       "PaperlessBilling     object\n",
       "PaymentMethod        object\n",
       "MonthlyCharges      float64\n",
       "TotalCharges        float64\n",
       "Churn                object\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Change the data type of the TotalCharges column from object to float\n",
    "df['TotalCharges']=df['TotalCharges'].astype('float')\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fffac57c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2283.3004408418697, 1397.475)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now we replace the null values in TotalCharges column with mean or median of TotalCharges column\n",
    "df['TotalCharges'].mean(),df['TotalCharges'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ff1ce6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender              0\n",
       "SeniorCitizen       0\n",
       "Partner             0\n",
       "Dependents          0\n",
       "tenure              0\n",
       "PhoneService        0\n",
       "MultipleLines       0\n",
       "InternetService     0\n",
       "OnlineSecurity      0\n",
       "OnlineBackup        0\n",
       "DeviceProtection    0\n",
       "TechSupport         0\n",
       "StreamingTV         0\n",
       "StreamingMovies     0\n",
       "Contract            0\n",
       "PaperlessBilling    0\n",
       "PaymentMethod       0\n",
       "MonthlyCharges      0\n",
       "TotalCharges        0\n",
       "Churn               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we see difference between mean and median of TotalCharges column so we replace the null values with median\n",
    "m=df['TotalCharges'].median()\n",
    "df['TotalCharges'].fillna(m,inplace=True)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e16cd1df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualise null values\n",
    "sb.heatmap(df.isnull())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5a5aab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     5174\n",
       "Yes    1869\n",
       "Name: Churn, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if Data is unbalanced\n",
    "df['Churn'].value_counts() #Clearly Data is unbalnced , so we balance it after scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06ec45cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualise unbalanced data\n",
    "f=df['Churn'].value_counts()\n",
    "sb.countplot(data=df,x='Churn')\n",
    "plt.yticks(f)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc82189c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender               object\n",
       "SeniorCitizen         int64\n",
       "Partner              object\n",
       "Dependents           object\n",
       "tenure                int64\n",
       "PhoneService         object\n",
       "MultipleLines        object\n",
       "InternetService      object\n",
       "OnlineSecurity       object\n",
       "OnlineBackup         object\n",
       "DeviceProtection     object\n",
       "TechSupport          object\n",
       "StreamingTV          object\n",
       "StreamingMovies      object\n",
       "Contract             object\n",
       "PaperlessBilling     object\n",
       "PaymentMethod        object\n",
       "MonthlyCharges      float64\n",
       "TotalCharges        float64\n",
       "Churn                object\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Seperate the numerical and categorical data\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01083746",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num=df.select_dtypes(('int64','float64'))\n",
    "df_cat=df.select_dtypes('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6ee7b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender              object\n",
       "Partner             object\n",
       "Dependents          object\n",
       "PhoneService        object\n",
       "MultipleLines       object\n",
       "InternetService     object\n",
       "OnlineSecurity      object\n",
       "OnlineBackup        object\n",
       "DeviceProtection    object\n",
       "TechSupport         object\n",
       "StreamingTV         object\n",
       "StreamingMovies     object\n",
       "Contract            object\n",
       "PaperlessBilling    object\n",
       "PaymentMethod       object\n",
       "Churn               object\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check data types of df_cat and df_num\n",
    "df_cat.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2487875b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SeniorCitizen       int64\n",
       "tenure              int64\n",
       "MonthlyCharges    float64\n",
       "TotalCharges      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_num.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3ece2e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply LabelRncoder on categorocal type data to convert it into numerical data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "columns=df_cat.columns\n",
    "for col in columns:\n",
    "    df_cat[col]=le.fit_transform(df_cat[[col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ffa2d110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  Partner  Dependents  PhoneService  MultipleLines  InternetService  \\\n",
       "0       0        1           0             0              1                0   \n",
       "1       1        0           0             1              0                0   \n",
       "2       1        0           0             1              0                0   \n",
       "3       1        0           0             0              1                0   \n",
       "4       0        0           0             1              0                1   \n",
       "\n",
       "   OnlineSecurity  OnlineBackup  DeviceProtection  TechSupport  StreamingTV  \\\n",
       "0               0             2                 0            0            0   \n",
       "1               2             0                 2            0            0   \n",
       "2               2             2                 0            0            0   \n",
       "3               2             0                 2            2            0   \n",
       "4               0             0                 0            0            0   \n",
       "\n",
       "   StreamingMovies  Contract  PaperlessBilling  PaymentMethod  Churn  \n",
       "0                0         0                 1              2      0  \n",
       "1                0         1                 0              3      0  \n",
       "2                0         0                 1              3      1  \n",
       "3                0         1                 0              0      0  \n",
       "4                0         0                 1              2      1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check df_cat \n",
    "df_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7bf1f840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>Churn</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>tenure</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  Partner  Dependents  PhoneService  MultipleLines  InternetService  \\\n",
       "0       0        1           0             0              1                0   \n",
       "1       1        0           0             1              0                0   \n",
       "2       1        0           0             1              0                0   \n",
       "3       1        0           0             0              1                0   \n",
       "4       0        0           0             1              0                1   \n",
       "\n",
       "   OnlineSecurity  OnlineBackup  DeviceProtection  TechSupport  StreamingTV  \\\n",
       "0               0             2                 0            0            0   \n",
       "1               2             0                 2            0            0   \n",
       "2               2             2                 0            0            0   \n",
       "3               2             0                 2            2            0   \n",
       "4               0             0                 0            0            0   \n",
       "\n",
       "   StreamingMovies  Contract  PaperlessBilling  PaymentMethod  Churn  \\\n",
       "0                0         0                 1              2      0   \n",
       "1                0         1                 0              3      0   \n",
       "2                0         0                 1              3      1   \n",
       "3                0         1                 0              0      0   \n",
       "4                0         0                 1              2      1   \n",
       "\n",
       "   SeniorCitizen  tenure  MonthlyCharges  TotalCharges  \n",
       "0              0       1           29.85         29.85  \n",
       "1              0      34           56.95       1889.50  \n",
       "2              0       2           53.85        108.15  \n",
       "3              0      45           42.30       1840.75  \n",
       "4              0       2           70.70        151.65  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Join df_cat and df_num\n",
    "df_new=pd.concat([df_cat,df_num],axis=1)\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ddc04d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select input and output \n",
    "X=df_new.drop('Churn',axis=1)\n",
    "Y=df_new['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a67164c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into 70-30\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "616a1328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4930, 19), (2113, 19))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check shape of X_train,X_test\n",
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "101877a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4930,), (2113,))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check shape of Y_train,Y_test\n",
    "Y_train.shape,Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bde41131",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply scaling on input columns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss=StandardScaler()\n",
    "X_train=ss.fit_transform(X_train)\n",
    "X_test=ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f73d1798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Now we balance the inbalanced data\n",
    "f=df['Churn'].value_counts()\n",
    "sb.countplot(data=df,x='Churn')\n",
    "plt.yticks(f)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e194ed0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use RandomOverSampling technique\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros=RandomOverSampler()\n",
    "X_train1,Y_train1=ros.fit_resample(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7cc8541d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7178, 19), (7178,))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for data balnacing\n",
    "X_train1.shape,Y_train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a2906382",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply random over sampler on testing data\n",
    "X_test1,Y_test1=ros.fit_resample(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3eb28e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3170, 19), (3170,))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for data balnacing\n",
    "X_test1.shape,Y_test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2a1bb076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3589\n",
       "1    3589\n",
       "Name: Churn, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for data balnacing\n",
    "Y_train1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c7119b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create user defined function\n",
    "def create_model(model):\n",
    "    model.fit(X_train1,Y_train1)\n",
    "    Y_pred=model.predict(X_test1)\n",
    "    print(classification_report(Y_test1,Y_pred))\n",
    "    print(confusion_matrix(Y_test1,Y_pred))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4246edef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import classification_report and confusion_matrix\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "73c4671e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.73      0.77      1585\n",
      "           1       0.76      0.83      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1157  428]\n",
      " [ 265 1320]]\n"
     ]
    }
   ],
   "source": [
    "#Train the model with LogisticRegression algorithm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression(random_state=1)\n",
    "lr=create_model(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b403266f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.83      0.73      1585\n",
      "           1       0.76      0.56      0.65      1585\n",
      "\n",
      "    accuracy                           0.69      3170\n",
      "   macro avg       0.71      0.69      0.69      3170\n",
      "weighted avg       0.71      0.69      0.69      3170\n",
      "\n",
      "[[1311  274]\n",
      " [ 696  889]]\n"
     ]
    }
   ],
   "source": [
    "#Train the model with DecisionTreeClassifier algorithm with Gini index \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc=DecisionTreeClassifier(random_state=1)\n",
    "dtc=create_model(dtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "61acfca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max depth : 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.58      0.70      1585\n",
      "           1       0.68      0.92      0.78      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.78      0.75      0.74      3170\n",
      "weighted avg       0.78      0.75      0.74      3170\n",
      "\n",
      "[[ 916  669]\n",
      " [ 132 1453]]\n",
      "Max depth : 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.74      0.74      1585\n",
      "           1       0.74      0.74      0.74      1585\n",
      "\n",
      "    accuracy                           0.74      3170\n",
      "   macro avg       0.74      0.74      0.74      3170\n",
      "weighted avg       0.74      0.74      0.74      3170\n",
      "\n",
      "[[1178  407]\n",
      " [ 406 1179]]\n",
      "Max depth : 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.70      0.74      1585\n",
      "           1       0.73      0.81      0.77      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.76      0.76      0.76      3170\n",
      "weighted avg       0.76      0.76      0.76      3170\n",
      "\n",
      "[[1116  469]\n",
      " [ 298 1287]]\n",
      "Max depth : 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.70      0.74      1585\n",
      "           1       0.73      0.81      0.77      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.76      0.76      0.75      3170\n",
      "weighted avg       0.76      0.76      0.75      3170\n",
      "\n",
      "[[1116  469]\n",
      " [ 307 1278]]\n",
      "Max depth : 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.77      0.77      1585\n",
      "           1       0.77      0.77      0.77      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1214  371]\n",
      " [ 370 1215]]\n",
      "Max depth : 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.69      0.74      1585\n",
      "           1       0.73      0.83      0.77      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.76      0.76      0.76      3170\n",
      "weighted avg       0.76      0.76      0.76      3170\n",
      "\n",
      "[[1092  493]\n",
      " [ 275 1310]]\n",
      "Max depth : 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.73      0.76      1585\n",
      "           1       0.75      0.81      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1151  434]\n",
      " [ 306 1279]]\n",
      "Max depth : 8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.71      0.74      1585\n",
      "           1       0.73      0.79      0.76      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.75      0.75      0.75      3170\n",
      "weighted avg       0.75      0.75      0.75      3170\n",
      "\n",
      "[[1122  463]\n",
      " [ 331 1254]]\n"
     ]
    }
   ],
   "source": [
    "#apply max_depth pruning technique on DecisionTreeClassifier with Gini index\n",
    "for i in range(1,9):\n",
    "    dtc_max_depth=DecisionTreeClassifier(max_depth=i,random_state=1)\n",
    "    print('Max depth :',i)\n",
    "    dtc_max_depth=create_model(dtc_max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "36ce9aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.69      0.74      1585\n",
      "           1       0.73      0.83      0.77      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.76      0.76      0.76      3170\n",
      "weighted avg       0.76      0.76      0.76      3170\n",
      "\n",
      "[[1092  493]\n",
      " [ 275 1310]]\n"
     ]
    }
   ],
   "source": [
    "#max_depth pruning technique on DecisionTreeClassifier with Gini index\n",
    "#max depth= 6 gives best recall value =0.82\n",
    "dtc_max_depth=DecisionTreeClassifier(max_depth=6,random_state=1)\n",
    "dtc_max_depth=create_model(dtc_max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7c323733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min_samples_leaf : 45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.74      0.75      1585\n",
      "           1       0.75      0.77      0.76      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.75      0.75      0.75      3170\n",
      "weighted avg       0.75      0.75      0.75      3170\n",
      "\n",
      "[[1176  409]\n",
      " [ 372 1213]]\n",
      "Min_samples_leaf : 46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.74      0.75      1585\n",
      "           1       0.75      0.77      0.76      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.75      0.75      0.75      3170\n",
      "weighted avg       0.75      0.75      0.75      3170\n",
      "\n",
      "[[1171  414]\n",
      " [ 369 1216]]\n",
      "Min_samples_leaf : 47\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.74      0.75      1585\n",
      "           1       0.74      0.77      0.75      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.75      0.75      0.75      3170\n",
      "weighted avg       0.75      0.75      0.75      3170\n",
      "\n",
      "[[1167  418]\n",
      " [ 372 1213]]\n",
      "Min_samples_leaf : 48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.74      0.75      1585\n",
      "           1       0.75      0.77      0.76      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.75      0.75      0.75      3170\n",
      "weighted avg       0.75      0.75      0.75      3170\n",
      "\n",
      "[[1173  412]\n",
      " [ 366 1219]]\n",
      "Min_samples_leaf : 49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.75      0.75      1585\n",
      "           1       0.75      0.77      0.76      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.76      0.76      0.76      3170\n",
      "weighted avg       0.76      0.76      0.76      3170\n",
      "\n",
      "[[1182  403]\n",
      " [ 368 1217]]\n",
      "Min_samples_leaf : 50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.74      0.75      1585\n",
      "           1       0.75      0.77      0.76      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.75      0.75      0.75      3170\n",
      "weighted avg       0.75      0.75      0.75      3170\n",
      "\n",
      "[[1177  408]\n",
      " [ 371 1214]]\n",
      "Min_samples_leaf : 51\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.74      0.75      1585\n",
      "           1       0.75      0.77      0.76      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.75      0.75      0.75      3170\n",
      "weighted avg       0.75      0.75      0.75      3170\n",
      "\n",
      "[[1177  408]\n",
      " [ 371 1214]]\n",
      "Min_samples_leaf : 52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.74      0.75      1585\n",
      "           1       0.75      0.77      0.76      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.76      0.76      0.76      3170\n",
      "weighted avg       0.76      0.76      0.76      3170\n",
      "\n",
      "[[1174  411]\n",
      " [ 364 1221]]\n",
      "Min_samples_leaf : 53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.76      1585\n",
      "           1       0.75      0.78      0.77      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.76      0.76      0.76      3170\n",
      "weighted avg       0.76      0.76      0.76      3170\n",
      "\n",
      "[[1177  408]\n",
      " [ 341 1244]]\n",
      "Min_samples_leaf : 54\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.76      1585\n",
      "           1       0.75      0.79      0.77      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.77      0.76      0.76      3170\n",
      "weighted avg       0.77      0.76      0.76      3170\n",
      "\n",
      "[[1179  406]\n",
      " [ 340 1245]]\n",
      "Min_samples_leaf : 55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.76      1585\n",
      "           1       0.75      0.79      0.77      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1168  417]\n",
      " [ 325 1260]]\n",
      "Min_samples_leaf : 56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.76      1585\n",
      "           1       0.75      0.79      0.77      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1168  417]\n",
      " [ 325 1260]]\n",
      "Min_samples_leaf : 57\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.76      1585\n",
      "           1       0.75      0.79      0.77      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.77      0.76      0.76      3170\n",
      "weighted avg       0.77      0.76      0.76      3170\n",
      "\n",
      "[[1169  416]\n",
      " [ 330 1255]]\n",
      "Min_samples_leaf : 58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.76      1585\n",
      "           1       0.75      0.79      0.77      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.77      0.76      0.76      3170\n",
      "weighted avg       0.77      0.76      0.76      3170\n",
      "\n",
      "[[1169  416]\n",
      " [ 330 1255]]\n",
      "Min_samples_leaf : 59\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.76      1585\n",
      "           1       0.75      0.79      0.77      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.76      0.76      0.76      3170\n",
      "weighted avg       0.76      0.76      0.76      3170\n",
      "\n",
      "[[1169  416]\n",
      " [ 333 1252]]\n",
      "Min_samples_leaf : 60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.75      0.76      1585\n",
      "           1       0.76      0.79      0.77      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1182  403]\n",
      " [ 333 1252]]\n",
      "Min_samples_leaf : 61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.75      0.76      1585\n",
      "           1       0.76      0.79      0.77      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1182  403]\n",
      " [ 333 1252]]\n",
      "Min_samples_leaf : 62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.75      0.76      1585\n",
      "           1       0.76      0.79      0.77      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1182  403]\n",
      " [ 333 1252]]\n",
      "Min_samples_leaf : 63\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.74      0.76      1585\n",
      "           1       0.75      0.81      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1167  418]\n",
      " [ 303 1282]]\n",
      "Min_samples_leaf : 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.74      0.76      1585\n",
      "           1       0.75      0.81      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1167  418]\n",
      " [ 303 1282]]\n",
      "Min_samples_leaf : 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76      1585\n",
      "           1       0.75      0.82      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1151  434]\n",
      " [ 283 1302]]\n",
      "Min_samples_leaf : 66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76      1585\n",
      "           1       0.75      0.82      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1151  434]\n",
      " [ 283 1302]]\n",
      "Min_samples_leaf : 67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76      1585\n",
      "           1       0.75      0.82      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1151  434]\n",
      " [ 283 1302]]\n",
      "Min_samples_leaf : 68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76      1585\n",
      "           1       0.75      0.82      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1151  434]\n",
      " [ 283 1302]]\n",
      "Min_samples_leaf : 69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76      1585\n",
      "           1       0.75      0.82      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1151  434]\n",
      " [ 283 1302]]\n",
      "Min_samples_leaf : 70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76      1585\n",
      "           1       0.75      0.82      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1151  434]\n",
      " [ 283 1302]]\n",
      "Min_samples_leaf : 71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76      1585\n",
      "           1       0.75      0.82      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1151  434]\n",
      " [ 283 1302]]\n",
      "Min_samples_leaf : 72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76      1585\n",
      "           1       0.75      0.82      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1151  434]\n",
      " [ 283 1302]]\n",
      "Min_samples_leaf : 73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.72      0.76      1585\n",
      "           1       0.75      0.83      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1143  442]\n",
      " [ 277 1308]]\n",
      "Min_samples_leaf : 74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.72      0.76      1585\n",
      "           1       0.75      0.83      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1143  442]\n",
      " [ 277 1308]]\n",
      "Min_samples_leaf : 75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.72      0.76      1585\n",
      "           1       0.75      0.83      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1144  441]\n",
      " [ 277 1308]]\n",
      "Min_samples_leaf : 76\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.72      0.76      1585\n",
      "           1       0.75      0.83      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1144  441]\n",
      " [ 277 1308]]\n",
      "Min_samples_leaf : 77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.72      0.76      1585\n",
      "           1       0.75      0.83      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1144  441]\n",
      " [ 277 1308]]\n",
      "Min_samples_leaf : 78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.72      0.76      1585\n",
      "           1       0.75      0.83      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1144  441]\n",
      " [ 277 1308]]\n",
      "Min_samples_leaf : 79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.72      0.76      1585\n",
      "           1       0.75      0.83      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1144  441]\n",
      " [ 277 1308]]\n",
      "Min_samples_leaf : 80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.72      0.76      1585\n",
      "           1       0.75      0.83      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1144  441]\n",
      " [ 277 1308]]\n",
      "Min_samples_leaf : 81\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.72      0.76      1585\n",
      "           1       0.75      0.83      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1144  441]\n",
      " [ 277 1308]]\n",
      "Min_samples_leaf : 82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.72      0.76      1585\n",
      "           1       0.75      0.83      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1144  441]\n",
      " [ 277 1308]]\n",
      "Min_samples_leaf : 83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.72      0.76      1585\n",
      "           1       0.75      0.83      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1144  441]\n",
      " [ 277 1308]]\n",
      "Min_samples_leaf : 84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.72      0.76      1585\n",
      "           1       0.75      0.83      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1144  441]\n",
      " [ 277 1308]]\n",
      "Min_samples_leaf : 85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.72      0.76      1585\n",
      "           1       0.75      0.83      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1144  441]\n",
      " [ 277 1308]]\n",
      "Min_samples_leaf : 86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76      1585\n",
      "           1       0.75      0.82      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1152  433]\n",
      " [ 287 1298]]\n",
      "Min_samples_leaf : 87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76      1585\n",
      "           1       0.75      0.82      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1152  433]\n",
      " [ 287 1298]]\n",
      "Min_samples_leaf : 88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76      1585\n",
      "           1       0.75      0.82      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1152  433]\n",
      " [ 287 1298]]\n",
      "Min_samples_leaf : 89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76      1585\n",
      "           1       0.75      0.82      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1152  433]\n",
      " [ 287 1298]]\n",
      "Min_samples_leaf : 90\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76      1585\n",
      "           1       0.75      0.82      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1152  433]\n",
      " [ 287 1298]]\n",
      "Min_samples_leaf : 91\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76      1585\n",
      "           1       0.75      0.82      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1152  433]\n",
      " [ 287 1298]]\n",
      "Min_samples_leaf : 92\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76      1585\n",
      "           1       0.75      0.82      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1152  433]\n",
      " [ 287 1298]]\n",
      "Min_samples_leaf : 93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76      1585\n",
      "           1       0.75      0.82      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1153  432]\n",
      " [ 287 1298]]\n",
      "Min_samples_leaf : 94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76      1585\n",
      "           1       0.75      0.82      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1153  432]\n",
      " [ 287 1298]]\n",
      "Min_samples_leaf : 95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76      1585\n",
      "           1       0.75      0.82      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1153  432]\n",
      " [ 287 1298]]\n",
      "Min_samples_leaf : 96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76      1585\n",
      "           1       0.75      0.82      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1153  432]\n",
      " [ 287 1298]]\n",
      "Min_samples_leaf : 97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76      1585\n",
      "           1       0.75      0.82      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1153  432]\n",
      " [ 287 1298]]\n",
      "Min_samples_leaf : 98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76      1585\n",
      "           1       0.75      0.82      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1154  431]\n",
      " [ 287 1298]]\n",
      "Min_samples_leaf : 99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.73      0.76      1585\n",
      "           1       0.75      0.81      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1162  423]\n",
      " [ 303 1282]]\n",
      "Min_samples_leaf : 100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.73      0.76      1585\n",
      "           1       0.75      0.81      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1162  423]\n",
      " [ 303 1282]]\n"
     ]
    }
   ],
   "source": [
    "#apply min_samples_leaf pruning technique on DecisionTreeClassifier with Gini index\n",
    "for i in range(45,101):\n",
    "    dtc_min_leaf=DecisionTreeClassifier(min_samples_leaf=i,random_state=1)\n",
    "    print('Min_samples_leaf :',i)\n",
    "    dtc_min_leaf=create_model(dtc_min_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f3ab1603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.74      0.76      1585\n",
      "           1       0.75      0.81      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1167  418]\n",
      " [ 303 1282]]\n"
     ]
    }
   ],
   "source": [
    "#Min samples leaf pruning technique on DecisionTreeClassifier with Gini index\n",
    "#Min_samples_leaf= 63 gives best recall = 0.81 \n",
    "dtc_min_leaf=DecisionTreeClassifier(min_samples_leaf=63,random_state=1)\n",
    "dtc_min_leaf=create_model(dtc_min_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e43dfff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.82      0.71      1585\n",
      "           1       0.74      0.52      0.61      1585\n",
      "\n",
      "    accuracy                           0.67      3170\n",
      "   macro avg       0.69      0.67      0.66      3170\n",
      "weighted avg       0.69      0.67      0.66      3170\n",
      "\n",
      "[[1299  286]\n",
      " [ 762  823]]\n"
     ]
    }
   ],
   "source": [
    "#Train the model with DecisionTreeClassifier algorithm with Entropy \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc2=DecisionTreeClassifier(random_state=1,criterion='entropy')\n",
    "dtc2=create_model(dtc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f9dbb39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max depth : 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.58      0.70      1585\n",
      "           1       0.68      0.92      0.78      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.78      0.75      0.74      3170\n",
      "weighted avg       0.78      0.75      0.74      3170\n",
      "\n",
      "[[ 916  669]\n",
      " [ 132 1453]]\n",
      "Max depth : 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.74      0.74      1585\n",
      "           1       0.74      0.74      0.74      1585\n",
      "\n",
      "    accuracy                           0.74      3170\n",
      "   macro avg       0.74      0.74      0.74      3170\n",
      "weighted avg       0.74      0.74      0.74      3170\n",
      "\n",
      "[[1178  407]\n",
      " [ 406 1179]]\n",
      "Max depth : 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.70      0.74      1585\n",
      "           1       0.73      0.81      0.77      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.76      0.76      0.76      3170\n",
      "weighted avg       0.76      0.76      0.76      3170\n",
      "\n",
      "[[1116  469]\n",
      " [ 298 1287]]\n",
      "Max depth : 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.74      0.75      1585\n",
      "           1       0.75      0.78      0.76      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.76      0.76      0.76      3170\n",
      "weighted avg       0.76      0.76      0.76      3170\n",
      "\n",
      "[[1171  414]\n",
      " [ 348 1237]]\n",
      "Max depth : 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.76      1585\n",
      "           1       0.77      0.76      0.76      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.76      0.76      0.76      3170\n",
      "weighted avg       0.76      0.76      0.76      3170\n",
      "\n",
      "[[1216  369]\n",
      " [ 381 1204]]\n",
      "Max depth : 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.71      0.76      1585\n",
      "           1       0.74      0.83      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1133  452]\n",
      " [ 276 1309]]\n",
      "Max depth : 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.72      0.75      1585\n",
      "           1       0.74      0.80      0.77      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.76      0.76      0.76      3170\n",
      "weighted avg       0.76      0.76      0.76      3170\n",
      "\n",
      "[[1148  437]\n",
      " [ 314 1271]]\n",
      "Max depth : 8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.74      0.75      1585\n",
      "           1       0.74      0.76      0.75      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.75      0.75      0.75      3170\n",
      "weighted avg       0.75      0.75      0.75      3170\n",
      "\n",
      "[[1168  417]\n",
      " [ 375 1210]]\n"
     ]
    }
   ],
   "source": [
    "#apply max_depth pruning technique on DecisionTreeClassifier with Entropy\n",
    "for i in range(1,9):\n",
    "    dtc2_max_depth=DecisionTreeClassifier(max_depth=i,random_state=1,criterion='entropy')\n",
    "    print('Max depth :',i)\n",
    "    dtc2_max_depth=create_model(dtc2_max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "54941644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.76      1585\n",
      "           1       0.77      0.76      0.76      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.76      0.76      0.76      3170\n",
      "weighted avg       0.76      0.76      0.76      3170\n",
      "\n",
      "[[1216  369]\n",
      " [ 381 1204]]\n"
     ]
    }
   ],
   "source": [
    "#max_depth pruning technique on DecisionTreeClassifier with Entropy\n",
    "#max depth= 5 gives best recall value =0.81\n",
    "dtc2_max_depth=DecisionTreeClassifier(max_depth=5,random_state=1,criterion='entropy')\n",
    "dtc2_max_depth=create_model(dtc2_max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "20e682b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min_samples_leaf : 45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.73      0.76      1585\n",
      "           1       0.75      0.80      0.77      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.77      0.76      0.76      3170\n",
      "weighted avg       0.77      0.76      0.76      3170\n",
      "\n",
      "[[1150  435]\n",
      " [ 310 1275]]\n",
      "Min_samples_leaf : 46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.72      0.75      1585\n",
      "           1       0.74      0.81      0.77      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.77      0.76      0.76      3170\n",
      "weighted avg       0.77      0.76      0.76      3170\n",
      "\n",
      "[[1141  444]\n",
      " [ 307 1278]]\n",
      "Min_samples_leaf : 47\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.72      0.75      1585\n",
      "           1       0.74      0.81      0.77      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.77      0.76      0.76      3170\n",
      "weighted avg       0.77      0.76      0.76      3170\n",
      "\n",
      "[[1141  444]\n",
      " [ 307 1278]]\n",
      "Min_samples_leaf : 48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.72      0.75      1585\n",
      "           1       0.74      0.81      0.78      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.77      0.76      0.76      3170\n",
      "weighted avg       0.77      0.76      0.76      3170\n",
      "\n",
      "[[1135  450]\n",
      " [ 296 1289]]\n",
      "Min_samples_leaf : 49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.72      0.76      1585\n",
      "           1       0.74      0.81      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1144  441]\n",
      " [ 298 1287]]\n",
      "Min_samples_leaf : 50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.72      0.76      1585\n",
      "           1       0.74      0.82      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1139  446]\n",
      " [ 286 1299]]\n",
      "Min_samples_leaf : 51\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.72      0.76      1585\n",
      "           1       0.74      0.82      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1139  446]\n",
      " [ 286 1299]]\n",
      "Min_samples_leaf : 52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.72      0.76      1585\n",
      "           1       0.74      0.82      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1139  446]\n",
      " [ 286 1299]]\n",
      "Min_samples_leaf : 53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.72      0.76      1585\n",
      "           1       0.75      0.82      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1145  440]\n",
      " [ 285 1300]]\n",
      "Min_samples_leaf : 54\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.72      0.76      1585\n",
      "           1       0.75      0.83      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1139  446]\n",
      " [ 277 1308]]\n",
      "Min_samples_leaf : 55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.72      0.76      1585\n",
      "           1       0.75      0.82      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1142  443]\n",
      " [ 279 1306]]\n",
      "Min_samples_leaf : 56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.73      0.76      1585\n",
      "           1       0.75      0.81      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1154  431]\n",
      " [ 307 1278]]\n",
      "Min_samples_leaf : 57\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.73      0.76      1585\n",
      "           1       0.75      0.80      0.77      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.77      0.76      0.76      3170\n",
      "weighted avg       0.77      0.76      0.76      3170\n",
      "\n",
      "[[1152  433]\n",
      " [ 312 1273]]\n",
      "Min_samples_leaf : 58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.73      0.76      1585\n",
      "           1       0.75      0.80      0.77      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.77      0.76      0.76      3170\n",
      "weighted avg       0.77      0.76      0.76      3170\n",
      "\n",
      "[[1152  433]\n",
      " [ 312 1273]]\n",
      "Min_samples_leaf : 59\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.73      0.75      1585\n",
      "           1       0.75      0.80      0.77      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.77      0.76      0.76      3170\n",
      "weighted avg       0.77      0.76      0.76      3170\n",
      "\n",
      "[[1152  433]\n",
      " [ 315 1270]]\n",
      "Min_samples_leaf : 60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.76      1585\n",
      "           1       0.75      0.79      0.77      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.76      0.76      0.76      3170\n",
      "weighted avg       0.76      0.76      0.76      3170\n",
      "\n",
      "[[1165  420]\n",
      " [ 330 1255]]\n",
      "Min_samples_leaf : 61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.76      1585\n",
      "           1       0.75      0.79      0.77      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.76      0.76      0.76      3170\n",
      "weighted avg       0.76      0.76      0.76      3170\n",
      "\n",
      "[[1165  420]\n",
      " [ 329 1256]]\n",
      "Min_samples_leaf : 62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.74      0.76      1585\n",
      "           1       0.75      0.81      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1167  418]\n",
      " [ 305 1280]]\n",
      "Min_samples_leaf : 63\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.74      0.76      1585\n",
      "           1       0.75      0.81      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1167  418]\n",
      " [ 305 1280]]\n",
      "Min_samples_leaf : 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.75      0.77      1585\n",
      "           1       0.76      0.80      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1185  400]\n",
      " [ 315 1270]]\n",
      "Min_samples_leaf : 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.74      0.77      1585\n",
      "           1       0.76      0.81      0.78      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1169  416]\n",
      " [ 295 1290]]\n",
      "Min_samples_leaf : 66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.74      0.76      1585\n",
      "           1       0.75      0.80      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1170  415]\n",
      " [ 312 1273]]\n",
      "Min_samples_leaf : 67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.74      0.76      1585\n",
      "           1       0.75      0.80      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1171  414]\n",
      " [ 312 1273]]\n",
      "Min_samples_leaf : 68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.74      0.76      1585\n",
      "           1       0.75      0.80      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1171  414]\n",
      " [ 312 1273]]\n",
      "Min_samples_leaf : 69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.74      0.76      1585\n",
      "           1       0.75      0.80      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1171  414]\n",
      " [ 312 1273]]\n",
      "Min_samples_leaf : 70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.74      0.76      1585\n",
      "           1       0.75      0.80      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1171  414]\n",
      " [ 312 1273]]\n",
      "Min_samples_leaf : 71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.75      0.76      1585\n",
      "           1       0.76      0.79      0.77      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1185  400]\n",
      " [ 333 1252]]\n",
      "Min_samples_leaf : 72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.75      0.76      1585\n",
      "           1       0.76      0.79      0.77      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1185  400]\n",
      " [ 333 1252]]\n",
      "Min_samples_leaf : 73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.75      0.76      1585\n",
      "           1       0.76      0.78      0.77      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1187  398]\n",
      " [ 343 1242]]\n",
      "Min_samples_leaf : 74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.75      0.76      1585\n",
      "           1       0.76      0.78      0.77      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.76      0.76      0.76      3170\n",
      "weighted avg       0.76      0.76      0.76      3170\n",
      "\n",
      "[[1190  395]\n",
      " [ 355 1230]]\n",
      "Min_samples_leaf : 75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.75      0.76      1585\n",
      "           1       0.76      0.78      0.77      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.76      0.76      0.76      3170\n",
      "weighted avg       0.76      0.76      0.76      3170\n",
      "\n",
      "[[1192  393]\n",
      " [ 355 1230]]\n",
      "Min_samples_leaf : 76\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.76      1585\n",
      "           1       0.75      0.79      0.77      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.76      0.76      0.76      3170\n",
      "weighted avg       0.76      0.76      0.76      3170\n",
      "\n",
      "[[1177  408]\n",
      " [ 339 1246]]\n",
      "Min_samples_leaf : 77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.76      1585\n",
      "           1       0.75      0.79      0.77      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1175  410]\n",
      " [ 329 1256]]\n",
      "Min_samples_leaf : 78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.76      1585\n",
      "           1       0.75      0.79      0.77      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1175  410]\n",
      " [ 329 1256]]\n",
      "Min_samples_leaf : 79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.73      0.76      1585\n",
      "           1       0.75      0.81      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1158  427]\n",
      " [ 302 1283]]\n",
      "Min_samples_leaf : 80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.73      0.76      1585\n",
      "           1       0.75      0.81      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1158  427]\n",
      " [ 302 1283]]\n",
      "Min_samples_leaf : 81\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.73      0.76      1585\n",
      "           1       0.75      0.81      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1158  427]\n",
      " [ 302 1283]]\n",
      "Min_samples_leaf : 82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.73      0.76      1585\n",
      "           1       0.75      0.81      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1158  427]\n",
      " [ 302 1283]]\n",
      "Min_samples_leaf : 83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.73      0.76      1585\n",
      "           1       0.75      0.81      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1158  427]\n",
      " [ 302 1283]]\n",
      "Min_samples_leaf : 84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.73      0.76      1585\n",
      "           1       0.75      0.81      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1158  427]\n",
      " [ 302 1283]]\n",
      "Min_samples_leaf : 85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.73      0.76      1585\n",
      "           1       0.75      0.81      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1158  427]\n",
      " [ 302 1283]]\n",
      "Min_samples_leaf : 86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.74      0.76      1585\n",
      "           1       0.75      0.80      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1167  418]\n",
      " [ 312 1273]]\n",
      "Min_samples_leaf : 87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.74      0.76      1585\n",
      "           1       0.75      0.80      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1167  418]\n",
      " [ 312 1273]]\n",
      "Min_samples_leaf : 88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.74      0.76      1585\n",
      "           1       0.75      0.80      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1167  418]\n",
      " [ 312 1273]]\n",
      "Min_samples_leaf : 89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.74      0.76      1585\n",
      "           1       0.75      0.80      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1167  418]\n",
      " [ 312 1273]]\n",
      "Min_samples_leaf : 90\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.74      0.76      1585\n",
      "           1       0.75      0.80      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1169  416]\n",
      " [ 314 1271]]\n",
      "Min_samples_leaf : 91\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.74      0.76      1585\n",
      "           1       0.75      0.80      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1169  416]\n",
      " [ 314 1271]]\n",
      "Min_samples_leaf : 92\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.74      0.76      1585\n",
      "           1       0.75      0.80      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1169  416]\n",
      " [ 314 1271]]\n",
      "Min_samples_leaf : 93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.74      0.76      1585\n",
      "           1       0.75      0.80      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1169  416]\n",
      " [ 314 1271]]\n",
      "Min_samples_leaf : 94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.74      0.76      1585\n",
      "           1       0.75      0.80      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1169  416]\n",
      " [ 314 1271]]\n",
      "Min_samples_leaf : 95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.74      0.76      1585\n",
      "           1       0.75      0.80      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1169  416]\n",
      " [ 314 1271]]\n",
      "Min_samples_leaf : 96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.74      0.76      1585\n",
      "           1       0.75      0.80      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1169  416]\n",
      " [ 314 1271]]\n",
      "Min_samples_leaf : 97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.74      0.76      1585\n",
      "           1       0.75      0.80      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1169  416]\n",
      " [ 314 1271]]\n",
      "Min_samples_leaf : 98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76      1585\n",
      "           1       0.75      0.82      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1150  435]\n",
      " [ 282 1303]]\n",
      "Min_samples_leaf : 99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.71      0.77      1585\n",
      "           1       0.75      0.86      0.80      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.79      0.78      0.78      3170\n",
      "weighted avg       0.79      0.78      0.78      3170\n",
      "\n",
      "[[1121  464]\n",
      " [ 220 1365]]\n",
      "Min_samples_leaf : 100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.71      0.77      1585\n",
      "           1       0.75      0.86      0.80      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.79      0.78      0.78      3170\n",
      "weighted avg       0.79      0.78      0.78      3170\n",
      "\n",
      "[[1121  464]\n",
      " [ 220 1365]]\n"
     ]
    }
   ],
   "source": [
    "#apply min_samples_leaf pruning technique on DecisionTreeClassifier with Entropy\n",
    "for i in range(45,101):\n",
    "    dtc2_min_leaf=DecisionTreeClassifier(min_samples_leaf=i,random_state=1,criterion='entropy')\n",
    "    print('Min_samples_leaf :',i)\n",
    "    dtc2_min_leaf=create_model(dtc2_min_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "25a039aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.72      0.76      1585\n",
      "           1       0.74      0.82      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1139  446]\n",
      " [ 286 1299]]\n"
     ]
    }
   ],
   "source": [
    "#Min samples leaf pruning technique on DecisionTreeClassifier with Entropy\n",
    "#Min_samples_leaf=51 gives best recall = 0.80\n",
    "dtc2_min_leaf=DecisionTreeClassifier(min_samples_leaf=51,random_state=1,criterion='entropy')\n",
    "dtc2_min_leaf=create_model(dtc2_min_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b41abbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the model with RandomForestClassifier Algorithm\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a92ff381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of decision Trees : 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.85      0.75      1585\n",
      "           1       0.80      0.58      0.67      1585\n",
      "\n",
      "    accuracy                           0.72      3170\n",
      "   macro avg       0.73      0.72      0.71      3170\n",
      "weighted avg       0.73      0.72      0.71      3170\n",
      "\n",
      "[[1355  230]\n",
      " [ 673  912]]\n",
      "No of decision Trees : 11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.83      0.76      1585\n",
      "           1       0.79      0.63      0.70      1585\n",
      "\n",
      "    accuracy                           0.73      3170\n",
      "   macro avg       0.74      0.73      0.73      3170\n",
      "weighted avg       0.74      0.73      0.73      3170\n",
      "\n",
      "[[1321  264]\n",
      " [ 592  993]]\n",
      "No of decision Trees : 12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.86      0.75      1585\n",
      "           1       0.80      0.59      0.68      1585\n",
      "\n",
      "    accuracy                           0.72      3170\n",
      "   macro avg       0.74      0.72      0.72      3170\n",
      "weighted avg       0.74      0.72      0.72      3170\n",
      "\n",
      "[[1356  229]\n",
      " [ 654  931]]\n",
      "No of decision Trees : 13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.83      0.75      1585\n",
      "           1       0.79      0.62      0.69      1585\n",
      "\n",
      "    accuracy                           0.73      3170\n",
      "   macro avg       0.74      0.73      0.72      3170\n",
      "weighted avg       0.74      0.73      0.72      3170\n",
      "\n",
      "[[1322  263]\n",
      " [ 601  984]]\n",
      "No of decision Trees : 14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.86      0.76      1585\n",
      "           1       0.80      0.59      0.68      1585\n",
      "\n",
      "    accuracy                           0.72      3170\n",
      "   macro avg       0.74      0.72      0.72      3170\n",
      "weighted avg       0.74      0.72      0.72      3170\n",
      "\n",
      "[[1358  227]\n",
      " [ 651  934]]\n",
      "No of decision Trees : 15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.83      0.75      1585\n",
      "           1       0.79      0.62      0.69      1585\n",
      "\n",
      "    accuracy                           0.73      3170\n",
      "   macro avg       0.74      0.73      0.72      3170\n",
      "weighted avg       0.74      0.73      0.72      3170\n",
      "\n",
      "[[1321  264]\n",
      " [ 607  978]]\n",
      "No of decision Trees : 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.85      0.76      1585\n",
      "           1       0.80      0.59      0.68      1585\n",
      "\n",
      "    accuracy                           0.72      3170\n",
      "   macro avg       0.74      0.72      0.72      3170\n",
      "weighted avg       0.74      0.72      0.72      3170\n",
      "\n",
      "[[1355  230]\n",
      " [ 649  936]]\n",
      "No of decision Trees : 17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.83      0.75      1585\n",
      "           1       0.79      0.62      0.69      1585\n",
      "\n",
      "    accuracy                           0.72      3170\n",
      "   macro avg       0.74      0.72      0.72      3170\n",
      "weighted avg       0.74      0.72      0.72      3170\n",
      "\n",
      "[[1321  264]\n",
      " [ 608  977]]\n",
      "No of decision Trees : 18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.85      0.75      1585\n",
      "           1       0.80      0.60      0.68      1585\n",
      "\n",
      "    accuracy                           0.72      3170\n",
      "   macro avg       0.74      0.72      0.72      3170\n",
      "weighted avg       0.74      0.72      0.72      3170\n",
      "\n",
      "[[1349  236]\n",
      " [ 640  945]]\n",
      "No of decision Trees : 19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.84      0.76      1585\n",
      "           1       0.79      0.62      0.70      1585\n",
      "\n",
      "    accuracy                           0.73      3170\n",
      "   macro avg       0.74      0.73      0.73      3170\n",
      "weighted avg       0.74      0.73      0.73      3170\n",
      "\n",
      "[[1331  254]\n",
      " [ 603  982]]\n",
      "No of decision Trees : 20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.86      0.76      1585\n",
      "           1       0.81      0.60      0.69      1585\n",
      "\n",
      "    accuracy                           0.73      3170\n",
      "   macro avg       0.74      0.73      0.72      3170\n",
      "weighted avg       0.74      0.73      0.72      3170\n",
      "\n",
      "[[1357  228]\n",
      " [ 638  947]]\n",
      "No of decision Trees : 21\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.84      0.76      1585\n",
      "           1       0.79      0.62      0.70      1585\n",
      "\n",
      "    accuracy                           0.73      3170\n",
      "   macro avg       0.74      0.73      0.73      3170\n",
      "weighted avg       0.74      0.73      0.73      3170\n",
      "\n",
      "[[1327  258]\n",
      " [ 595  990]]\n",
      "No of decision Trees : 22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.85      0.76      1585\n",
      "           1       0.80      0.60      0.69      1585\n",
      "\n",
      "    accuracy                           0.73      3170\n",
      "   macro avg       0.74      0.73      0.72      3170\n",
      "weighted avg       0.74      0.73      0.72      3170\n",
      "\n",
      "[[1353  232]\n",
      " [ 634  951]]\n",
      "No of decision Trees : 23\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.84      0.76      1585\n",
      "           1       0.80      0.63      0.70      1585\n",
      "\n",
      "    accuracy                           0.74      3170\n",
      "   macro avg       0.75      0.74      0.73      3170\n",
      "weighted avg       0.75      0.74      0.73      3170\n",
      "\n",
      "[[1330  255]\n",
      " [ 585 1000]]\n",
      "No of decision Trees : 24\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.85      0.76      1585\n",
      "           1       0.81      0.61      0.69      1585\n",
      "\n",
      "    accuracy                           0.73      3170\n",
      "   macro avg       0.75      0.73      0.73      3170\n",
      "weighted avg       0.75      0.73      0.73      3170\n",
      "\n",
      "[[1354  231]\n",
      " [ 619  966]]\n",
      "No of decision Trees : 25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.84      0.76      1585\n",
      "           1       0.79      0.63      0.70      1585\n",
      "\n",
      "    accuracy                           0.73      3170\n",
      "   macro avg       0.74      0.73      0.73      3170\n",
      "weighted avg       0.74      0.73      0.73      3170\n",
      "\n",
      "[[1328  257]\n",
      " [ 590  995]]\n",
      "No of decision Trees : 26\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.85      0.76      1585\n",
      "           1       0.81      0.60      0.69      1585\n",
      "\n",
      "    accuracy                           0.73      3170\n",
      "   macro avg       0.74      0.73      0.72      3170\n",
      "weighted avg       0.74      0.73      0.72      3170\n",
      "\n",
      "[[1354  231]\n",
      " [ 628  957]]\n",
      "No of decision Trees : 27\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.84      0.76      1585\n",
      "           1       0.80      0.63      0.70      1585\n",
      "\n",
      "    accuracy                           0.74      3170\n",
      "   macro avg       0.75      0.74      0.73      3170\n",
      "weighted avg       0.75      0.74      0.73      3170\n",
      "\n",
      "[[1339  246]\n",
      " [ 590  995]]\n",
      "No of decision Trees : 28\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.85      0.76      1585\n",
      "           1       0.80      0.61      0.69      1585\n",
      "\n",
      "    accuracy                           0.73      3170\n",
      "   macro avg       0.74      0.73      0.72      3170\n",
      "weighted avg       0.74      0.73      0.72      3170\n",
      "\n",
      "[[1350  235]\n",
      " [ 626  959]]\n",
      "No of decision Trees : 29\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.84      0.76      1585\n",
      "           1       0.80      0.62      0.70      1585\n",
      "\n",
      "    accuracy                           0.73      3170\n",
      "   macro avg       0.74      0.73      0.73      3170\n",
      "weighted avg       0.74      0.73      0.73      3170\n",
      "\n",
      "[[1333  252]\n",
      " [ 599  986]]\n",
      "No of decision Trees : 30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.85      0.76      1585\n",
      "           1       0.80      0.61      0.70      1585\n",
      "\n",
      "    accuracy                           0.73      3170\n",
      "   macro avg       0.75      0.73      0.73      3170\n",
      "weighted avg       0.75      0.73      0.73      3170\n",
      "\n",
      "[[1348  237]\n",
      " [ 614  971]]\n",
      "No of decision Trees : 31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.84      0.76      1585\n",
      "           1       0.80      0.62      0.70      1585\n",
      "\n",
      "    accuracy                           0.73      3170\n",
      "   macro avg       0.75      0.73      0.73      3170\n",
      "weighted avg       0.75      0.73      0.73      3170\n",
      "\n",
      "[[1336  249]\n",
      " [ 596  989]]\n",
      "No of decision Trees : 32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.85      0.76      1585\n",
      "           1       0.81      0.61      0.69      1585\n",
      "\n",
      "    accuracy                           0.73      3170\n",
      "   macro avg       0.75      0.73      0.73      3170\n",
      "weighted avg       0.75      0.73      0.73      3170\n",
      "\n",
      "[[1352  233]\n",
      " [ 619  966]]\n",
      "No of decision Trees : 33\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.85      0.76      1585\n",
      "           1       0.80      0.63      0.70      1585\n",
      "\n",
      "    accuracy                           0.74      3170\n",
      "   macro avg       0.75      0.74      0.73      3170\n",
      "weighted avg       0.75      0.74      0.73      3170\n",
      "\n",
      "[[1340  245]\n",
      " [ 594  991]]\n",
      "No of decision Trees : 34\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.85      0.76      1585\n",
      "           1       0.81      0.61      0.69      1585\n",
      "\n",
      "    accuracy                           0.73      3170\n",
      "   macro avg       0.75      0.73      0.73      3170\n",
      "weighted avg       0.75      0.73      0.73      3170\n",
      "\n",
      "[[1353  232]\n",
      " [ 619  966]]\n",
      "No of decision Trees : 35\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.84      0.76      1585\n",
      "           1       0.80      0.63      0.71      1585\n",
      "\n",
      "    accuracy                           0.74      3170\n",
      "   macro avg       0.75      0.74      0.73      3170\n",
      "weighted avg       0.75      0.74      0.73      3170\n",
      "\n",
      "[[1336  249]\n",
      " [ 586  999]]\n",
      "No of decision Trees : 36\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.86      0.76      1585\n",
      "           1       0.81      0.61      0.70      1585\n",
      "\n",
      "    accuracy                           0.73      3170\n",
      "   macro avg       0.75      0.73      0.73      3170\n",
      "weighted avg       0.75      0.73      0.73      3170\n",
      "\n",
      "[[1359  226]\n",
      " [ 617  968]]\n",
      "No of decision Trees : 37\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.85      0.77      1585\n",
      "           1       0.81      0.64      0.72      1585\n",
      "\n",
      "    accuracy                           0.74      3170\n",
      "   macro avg       0.76      0.74      0.74      3170\n",
      "weighted avg       0.76      0.74      0.74      3170\n",
      "\n",
      "[[1343  242]\n",
      " [ 568 1017]]\n",
      "No of decision Trees : 38\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.85      0.76      1585\n",
      "           1       0.81      0.62      0.70      1585\n",
      "\n",
      "    accuracy                           0.74      3170\n",
      "   macro avg       0.75      0.74      0.73      3170\n",
      "weighted avg       0.75      0.74      0.73      3170\n",
      "\n",
      "[[1354  231]\n",
      " [ 608  977]]\n",
      "No of decision Trees : 39\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.85      0.77      1585\n",
      "           1       0.81      0.64      0.72      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.76      0.75      0.74      3170\n",
      "weighted avg       0.76      0.75      0.74      3170\n",
      "\n",
      "[[1345  240]\n",
      " [ 565 1020]]\n",
      "No of decision Trees : 40\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.86      0.77      1585\n",
      "           1       0.81      0.63      0.71      1585\n",
      "\n",
      "    accuracy                           0.74      3170\n",
      "   macro avg       0.76      0.74      0.74      3170\n",
      "weighted avg       0.76      0.74      0.74      3170\n",
      "\n",
      "[[1356  229]\n",
      " [ 585 1000]]\n",
      "No of decision Trees : 41\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.85      0.77      1585\n",
      "           1       0.81      0.65      0.72      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.76      0.75      0.74      3170\n",
      "weighted avg       0.76      0.75      0.74      3170\n",
      "\n",
      "[[1344  241]\n",
      " [ 562 1023]]\n",
      "No of decision Trees : 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.85      0.77      1585\n",
      "           1       0.81      0.63      0.71      1585\n",
      "\n",
      "    accuracy                           0.74      3170\n",
      "   macro avg       0.75      0.74      0.74      3170\n",
      "weighted avg       0.75      0.74      0.74      3170\n",
      "\n",
      "[[1353  232]\n",
      " [ 593  992]]\n",
      "No of decision Trees : 43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.85      0.77      1585\n",
      "           1       0.81      0.64      0.72      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.76      0.75      0.74      3170\n",
      "weighted avg       0.76      0.75      0.74      3170\n",
      "\n",
      "[[1347  238]\n",
      " [ 567 1018]]\n",
      "No of decision Trees : 44\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.85      0.76      1585\n",
      "           1       0.81      0.62      0.70      1585\n",
      "\n",
      "    accuracy                           0.74      3170\n",
      "   macro avg       0.75      0.74      0.73      3170\n",
      "weighted avg       0.75      0.74      0.73      3170\n",
      "\n",
      "[[1352  233]\n",
      " [ 603  982]]\n",
      "No of decision Trees : 45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.85      0.76      1585\n",
      "           1       0.80      0.63      0.70      1585\n",
      "\n",
      "    accuracy                           0.74      3170\n",
      "   macro avg       0.75      0.74      0.73      3170\n",
      "weighted avg       0.75      0.74      0.73      3170\n",
      "\n",
      "[[1342  243]\n",
      " [ 594  991]]\n",
      "No of decision Trees : 46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.85      0.76      1585\n",
      "           1       0.81      0.62      0.70      1585\n",
      "\n",
      "    accuracy                           0.74      3170\n",
      "   macro avg       0.75      0.74      0.73      3170\n",
      "weighted avg       0.75      0.74      0.73      3170\n",
      "\n",
      "[[1352  233]\n",
      " [ 602  983]]\n",
      "No of decision Trees : 47\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.85      0.77      1585\n",
      "           1       0.81      0.63      0.71      1585\n",
      "\n",
      "    accuracy                           0.74      3170\n",
      "   macro avg       0.75      0.74      0.74      3170\n",
      "weighted avg       0.75      0.74      0.74      3170\n",
      "\n",
      "[[1344  241]\n",
      " [ 583 1002]]\n",
      "No of decision Trees : 48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.85      0.76      1585\n",
      "           1       0.81      0.62      0.70      1585\n",
      "\n",
      "    accuracy                           0.74      3170\n",
      "   macro avg       0.75      0.74      0.73      3170\n",
      "weighted avg       0.75      0.74      0.73      3170\n",
      "\n",
      "[[1351  234]\n",
      " [ 598  987]]\n",
      "No of decision Trees : 49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.85      0.77      1585\n",
      "           1       0.81      0.64      0.71      1585\n",
      "\n",
      "    accuracy                           0.74      3170\n",
      "   macro avg       0.75      0.74      0.74      3170\n",
      "weighted avg       0.75      0.74      0.74      3170\n",
      "\n",
      "[[1343  242]\n",
      " [ 573 1012]]\n",
      "No of decision Trees : 50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.85      0.76      1585\n",
      "           1       0.81      0.62      0.70      1585\n",
      "\n",
      "    accuracy                           0.74      3170\n",
      "   macro avg       0.75      0.74      0.73      3170\n",
      "weighted avg       0.75      0.74      0.73      3170\n",
      "\n",
      "[[1350  235]\n",
      " [ 598  987]]\n",
      "No of decision Trees : 51\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.85      0.77      1585\n",
      "           1       0.81      0.64      0.71      1585\n",
      "\n",
      "    accuracy                           0.74      3170\n",
      "   macro avg       0.75      0.74      0.74      3170\n",
      "weighted avg       0.75      0.74      0.74      3170\n",
      "\n",
      "[[1344  241]\n",
      " [ 577 1008]]\n",
      "No of decision Trees : 52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.85      0.76      1585\n",
      "           1       0.81      0.62      0.70      1585\n",
      "\n",
      "    accuracy                           0.74      3170\n",
      "   macro avg       0.75      0.74      0.73      3170\n",
      "weighted avg       0.75      0.74      0.73      3170\n",
      "\n",
      "[[1350  235]\n",
      " [ 599  986]]\n",
      "No of decision Trees : 53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.85      0.77      1585\n",
      "           1       0.81      0.64      0.71      1585\n",
      "\n",
      "    accuracy                           0.74      3170\n",
      "   macro avg       0.75      0.74      0.74      3170\n",
      "weighted avg       0.75      0.74      0.74      3170\n",
      "\n",
      "[[1344  241]\n",
      " [ 573 1012]]\n",
      "No of decision Trees : 54\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.85      0.77      1585\n",
      "           1       0.81      0.62      0.70      1585\n",
      "\n",
      "    accuracy                           0.74      3170\n",
      "   macro avg       0.75      0.74      0.74      3170\n",
      "weighted avg       0.75      0.74      0.74      3170\n",
      "\n",
      "[[1351  234]\n",
      " [ 595  990]]\n",
      "No of decision Trees : 55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.85      0.77      1585\n",
      "           1       0.81      0.64      0.71      1585\n",
      "\n",
      "    accuracy                           0.74      3170\n",
      "   macro avg       0.75      0.74      0.74      3170\n",
      "weighted avg       0.75      0.74      0.74      3170\n",
      "\n",
      "[[1343  242]\n",
      " [ 578 1007]]\n",
      "No of decision Trees : 56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.85      0.77      1585\n",
      "           1       0.81      0.62      0.70      1585\n",
      "\n",
      "    accuracy                           0.74      3170\n",
      "   macro avg       0.75      0.74      0.73      3170\n",
      "weighted avg       0.75      0.74      0.73      3170\n",
      "\n",
      "[[1355  230]\n",
      " [ 599  986]]\n",
      "No of decision Trees : 57\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.85      0.77      1585\n",
      "           1       0.81      0.64      0.71      1585\n",
      "\n",
      "    accuracy                           0.74      3170\n",
      "   macro avg       0.76      0.74      0.74      3170\n",
      "weighted avg       0.76      0.74      0.74      3170\n",
      "\n",
      "[[1350  235]\n",
      " [ 578 1007]]\n",
      "No of decision Trees : 58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.85      0.77      1585\n",
      "           1       0.81      0.63      0.71      1585\n",
      "\n",
      "    accuracy                           0.74      3170\n",
      "   macro avg       0.75      0.74      0.74      3170\n",
      "weighted avg       0.75      0.74      0.74      3170\n",
      "\n",
      "[[1353  232]\n",
      " [ 588  997]]\n",
      "No of decision Trees : 59\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.85      0.77      1585\n",
      "           1       0.81      0.64      0.71      1585\n",
      "\n",
      "    accuracy                           0.74      3170\n",
      "   macro avg       0.76      0.74      0.74      3170\n",
      "weighted avg       0.76      0.74      0.74      3170\n",
      "\n",
      "[[1345  240]\n",
      " [ 572 1013]]\n",
      "No of decision Trees : 60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.85      0.77      1585\n",
      "           1       0.81      0.63      0.71      1585\n",
      "\n",
      "    accuracy                           0.74      3170\n",
      "   macro avg       0.75      0.74      0.74      3170\n",
      "weighted avg       0.75      0.74      0.74      3170\n",
      "\n",
      "[[1350  235]\n",
      " [ 592  993]]\n",
      "No of decision Trees : 61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.85      0.77      1585\n",
      "           1       0.81      0.64      0.71      1585\n",
      "\n",
      "    accuracy                           0.74      3170\n",
      "   macro avg       0.75      0.74      0.74      3170\n",
      "weighted avg       0.75      0.74      0.74      3170\n",
      "\n",
      "[[1342  243]\n",
      " [ 574 1011]]\n",
      "No of decision Trees : 62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.85      0.77      1585\n",
      "           1       0.81      0.63      0.71      1585\n",
      "\n",
      "    accuracy                           0.74      3170\n",
      "   macro avg       0.75      0.74      0.74      3170\n",
      "weighted avg       0.75      0.74      0.74      3170\n",
      "\n",
      "[[1349  236]\n",
      " [ 587  998]]\n",
      "No of decision Trees : 63\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.85      0.77      1585\n",
      "           1       0.81      0.64      0.71      1585\n",
      "\n",
      "    accuracy                           0.74      3170\n",
      "   macro avg       0.75      0.74      0.74      3170\n",
      "weighted avg       0.75      0.74      0.74      3170\n",
      "\n",
      "[[1344  241]\n",
      " [ 575 1010]]\n",
      "No of decision Trees : 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.85      0.77      1585\n",
      "           1       0.81      0.63      0.71      1585\n",
      "\n",
      "    accuracy                           0.74      3170\n",
      "   macro avg       0.75      0.74      0.74      3170\n",
      "weighted avg       0.75      0.74      0.74      3170\n",
      "\n",
      "[[1350  235]\n",
      " [ 581 1004]]\n",
      "No of decision Trees : 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.84      0.76      1585\n",
      "           1       0.80      0.64      0.71      1585\n",
      "\n",
      "    accuracy                           0.74      3170\n",
      "   macro avg       0.75      0.74      0.74      3170\n",
      "weighted avg       0.75      0.74      0.74      3170\n",
      "\n",
      "[[1334  251]\n",
      " [ 572 1013]]\n",
      "No of decision Trees : 66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.85      0.76      1585\n",
      "           1       0.80      0.63      0.70      1585\n",
      "\n",
      "    accuracy                           0.74      3170\n",
      "   macro avg       0.75      0.74      0.73      3170\n",
      "weighted avg       0.75      0.74      0.73      3170\n",
      "\n",
      "[[1343  242]\n",
      " [ 593  992]]\n",
      "No of decision Trees : 67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.84      0.76      1585\n",
      "           1       0.80      0.63      0.71      1585\n",
      "\n",
      "    accuracy                           0.74      3170\n",
      "   macro avg       0.75      0.74      0.74      3170\n",
      "weighted avg       0.75      0.74      0.74      3170\n",
      "\n",
      "[[1337  248]\n",
      " [ 580 1005]]\n",
      "No of decision Trees : 68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.85      0.76      1585\n",
      "           1       0.80      0.62      0.70      1585\n",
      "\n",
      "    accuracy                           0.74      3170\n",
      "   macro avg       0.75      0.74      0.73      3170\n",
      "weighted avg       0.75      0.74      0.73      3170\n",
      "\n",
      "[[1345  240]\n",
      " [ 598  987]]\n",
      "No of decision Trees : 69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.84      0.77      1585\n",
      "           1       0.81      0.64      0.71      1585\n",
      "\n",
      "    accuracy                           0.74      3170\n",
      "   macro avg       0.75      0.74      0.74      3170\n",
      "weighted avg       0.75      0.74      0.74      3170\n",
      "\n",
      "[[1339  246]\n",
      " [ 569 1016]]\n",
      "No of decision Trees : 70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.85      0.76      1585\n",
      "           1       0.81      0.63      0.71      1585\n",
      "\n",
      "    accuracy                           0.74      3170\n",
      "   macro avg       0.75      0.74      0.73      3170\n",
      "weighted avg       0.75      0.74      0.73      3170\n",
      "\n",
      "[[1347  238]\n",
      " [ 592  993]]\n",
      "No of decision Trees : 71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.84      0.77      1585\n",
      "           1       0.80      0.64      0.71      1585\n",
      "\n",
      "    accuracy                           0.74      3170\n",
      "   macro avg       0.75      0.74      0.74      3170\n",
      "weighted avg       0.75      0.74      0.74      3170\n",
      "\n",
      "[[1338  247]\n",
      " [ 567 1018]]\n",
      "No of decision Trees : 72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.85      0.77      1585\n",
      "           1       0.81      0.63      0.71      1585\n",
      "\n",
      "    accuracy                           0.74      3170\n",
      "   macro avg       0.75      0.74      0.74      3170\n",
      "weighted avg       0.75      0.74      0.74      3170\n",
      "\n",
      "[[1348  237]\n",
      " [ 580 1005]]\n",
      "No of decision Trees : 73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.85      0.77      1585\n",
      "           1       0.81      0.64      0.71      1585\n",
      "\n",
      "    accuracy                           0.74      3170\n",
      "   macro avg       0.75      0.74      0.74      3170\n",
      "weighted avg       0.75      0.74      0.74      3170\n",
      "\n",
      "[[1340  245]\n",
      " [ 572 1013]]\n",
      "No of decision Trees : 74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.85      0.77      1585\n",
      "           1       0.81      0.63      0.71      1585\n",
      "\n",
      "    accuracy                           0.74      3170\n",
      "   macro avg       0.75      0.74      0.74      3170\n",
      "weighted avg       0.75      0.74      0.74      3170\n",
      "\n",
      "[[1350  235]\n",
      " [ 586  999]]\n",
      "No of decision Trees : 75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.85      0.77      1585\n",
      "           1       0.81      0.64      0.72      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.76      0.75      0.74      3170\n",
      "weighted avg       0.76      0.75      0.74      3170\n",
      "\n",
      "[[1345  240]\n",
      " [ 565 1020]]\n",
      "No of decision Trees : 76\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.85      0.77      1585\n",
      "           1       0.81      0.64      0.72      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.76      0.75      0.74      3170\n",
      "weighted avg       0.76      0.75      0.74      3170\n",
      "\n",
      "[[1348  237]\n",
      " [ 571 1014]]\n",
      "No of decision Trees : 77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.85      0.77      1585\n",
      "           1       0.81      0.65      0.72      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.76      0.75      0.74      3170\n",
      "weighted avg       0.76      0.75      0.74      3170\n",
      "\n",
      "[[1343  242]\n",
      " [ 562 1023]]\n",
      "No of decision Trees : 78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.85      0.77      1585\n",
      "           1       0.81      0.64      0.71      1585\n",
      "\n",
      "    accuracy                           0.74      3170\n",
      "   macro avg       0.75      0.74      0.74      3170\n",
      "weighted avg       0.75      0.74      0.74      3170\n",
      "\n",
      "[[1345  240]\n",
      " [ 573 1012]]\n",
      "No of decision Trees : 79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.85      0.77      1585\n",
      "           1       0.81      0.65      0.72      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.76      0.75      0.75      3170\n",
      "weighted avg       0.76      0.75      0.75      3170\n",
      "\n",
      "[[1344  241]\n",
      " [ 557 1028]]\n",
      "No of decision Trees : 80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.85      0.77      1585\n",
      "           1       0.81      0.64      0.72      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.76      0.75      0.74      3170\n",
      "weighted avg       0.76      0.75      0.74      3170\n",
      "\n",
      "[[1348  237]\n",
      " [ 568 1017]]\n",
      "No of decision Trees : 81\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.85      0.77      1585\n",
      "           1       0.81      0.65      0.72      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.76      0.75      0.74      3170\n",
      "weighted avg       0.76      0.75      0.74      3170\n",
      "\n",
      "[[1342  243]\n",
      " [ 562 1023]]\n",
      "No of decision Trees : 82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.85      0.77      1585\n",
      "           1       0.81      0.64      0.72      1585\n",
      "\n",
      "    accuracy                           0.74      3170\n",
      "   macro avg       0.76      0.74      0.74      3170\n",
      "weighted avg       0.76      0.74      0.74      3170\n",
      "\n",
      "[[1346  239]\n",
      " [ 570 1015]]\n",
      "No of decision Trees : 83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.85      0.77      1585\n",
      "           1       0.81      0.65      0.72      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.76      0.75      0.74      3170\n",
      "weighted avg       0.76      0.75      0.74      3170\n",
      "\n",
      "[[1341  244]\n",
      " [ 560 1025]]\n",
      "No of decision Trees : 84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.85      0.77      1585\n",
      "           1       0.81      0.64      0.72      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.76      0.75      0.74      3170\n",
      "weighted avg       0.76      0.75      0.74      3170\n",
      "\n",
      "[[1346  239]\n",
      " [ 563 1022]]\n",
      "No of decision Trees : 85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.85      0.77      1585\n",
      "           1       0.81      0.65      0.72      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.76      0.75      0.74      3170\n",
      "weighted avg       0.76      0.75      0.74      3170\n",
      "\n",
      "[[1341  244]\n",
      " [ 561 1024]]\n",
      "No of decision Trees : 86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.85      0.77      1585\n",
      "           1       0.81      0.64      0.72      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.76      0.75      0.74      3170\n",
      "weighted avg       0.76      0.75      0.74      3170\n",
      "\n",
      "[[1346  239]\n",
      " [ 568 1017]]\n",
      "No of decision Trees : 87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.84      0.77      1585\n",
      "           1       0.81      0.64      0.72      1585\n",
      "\n",
      "    accuracy                           0.74      3170\n",
      "   macro avg       0.75      0.74      0.74      3170\n",
      "weighted avg       0.75      0.74      0.74      3170\n",
      "\n",
      "[[1339  246]\n",
      " [ 564 1021]]\n",
      "No of decision Trees : 88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.85      0.77      1585\n",
      "           1       0.81      0.64      0.71      1585\n",
      "\n",
      "    accuracy                           0.74      3170\n",
      "   macro avg       0.76      0.74      0.74      3170\n",
      "weighted avg       0.76      0.74      0.74      3170\n",
      "\n",
      "[[1344  241]\n",
      " [ 570 1015]]\n",
      "No of decision Trees : 89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.84      0.77      1585\n",
      "           1       0.81      0.64      0.72      1585\n",
      "\n",
      "    accuracy                           0.74      3170\n",
      "   macro avg       0.75      0.74      0.74      3170\n",
      "weighted avg       0.75      0.74      0.74      3170\n",
      "\n",
      "[[1338  247]\n",
      " [ 563 1022]]\n",
      "No of decision Trees : 90\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.85      0.77      1585\n",
      "           1       0.81      0.64      0.72      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.76      0.75      0.74      3170\n",
      "weighted avg       0.76      0.75      0.74      3170\n",
      "\n",
      "[[1345  240]\n",
      " [ 567 1018]]\n",
      "No of decision Trees : 91\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.85      0.77      1585\n",
      "           1       0.81      0.64      0.72      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.76      0.75      0.74      3170\n",
      "weighted avg       0.76      0.75      0.74      3170\n",
      "\n",
      "[[1343  242]\n",
      " [ 566 1019]]\n",
      "No of decision Trees : 92\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.85      0.77      1585\n",
      "           1       0.81      0.64      0.71      1585\n",
      "\n",
      "    accuracy                           0.74      3170\n",
      "   macro avg       0.75      0.74      0.74      3170\n",
      "weighted avg       0.75      0.74      0.74      3170\n",
      "\n",
      "[[1344  241]\n",
      " [ 571 1014]]\n",
      "No of decision Trees : 93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.85      0.77      1585\n",
      "           1       0.81      0.64      0.72      1585\n",
      "\n",
      "    accuracy                           0.74      3170\n",
      "   macro avg       0.76      0.74      0.74      3170\n",
      "weighted avg       0.76      0.74      0.74      3170\n",
      "\n",
      "[[1341  244]\n",
      " [ 566 1019]]\n",
      "No of decision Trees : 94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.85      0.77      1585\n",
      "           1       0.81      0.64      0.72      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.76      0.75      0.74      3170\n",
      "weighted avg       0.76      0.75      0.74      3170\n",
      "\n",
      "[[1344  241]\n",
      " [ 567 1018]]\n",
      "No of decision Trees : 95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.84      0.77      1585\n",
      "           1       0.81      0.64      0.72      1585\n",
      "\n",
      "    accuracy                           0.74      3170\n",
      "   macro avg       0.75      0.74      0.74      3170\n",
      "weighted avg       0.75      0.74      0.74      3170\n",
      "\n",
      "[[1338  247]\n",
      " [ 565 1020]]\n",
      "No of decision Trees : 96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.85      0.77      1585\n",
      "           1       0.81      0.64      0.72      1585\n",
      "\n",
      "    accuracy                           0.74      3170\n",
      "   macro avg       0.76      0.74      0.74      3170\n",
      "weighted avg       0.76      0.74      0.74      3170\n",
      "\n",
      "[[1341  244]\n",
      " [ 566 1019]]\n",
      "No of decision Trees : 97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.84      0.77      1585\n",
      "           1       0.80      0.64      0.71      1585\n",
      "\n",
      "    accuracy                           0.74      3170\n",
      "   macro avg       0.75      0.74      0.74      3170\n",
      "weighted avg       0.75      0.74      0.74      3170\n",
      "\n",
      "[[1336  249]\n",
      " [ 566 1019]]\n",
      "No of decision Trees : 98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.85      0.77      1585\n",
      "           1       0.81      0.64      0.71      1585\n",
      "\n",
      "    accuracy                           0.74      3170\n",
      "   macro avg       0.75      0.74      0.74      3170\n",
      "weighted avg       0.75      0.74      0.74      3170\n",
      "\n",
      "[[1340  245]\n",
      " [ 569 1016]]\n",
      "No of decision Trees : 99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.84      0.77      1585\n",
      "           1       0.80      0.64      0.71      1585\n",
      "\n",
      "    accuracy                           0.74      3170\n",
      "   macro avg       0.75      0.74      0.74      3170\n",
      "weighted avg       0.75      0.74      0.74      3170\n",
      "\n",
      "[[1333  252]\n",
      " [ 566 1019]]\n",
      "No of decision Trees : 100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.84      0.77      1585\n",
      "           1       0.80      0.64      0.71      1585\n",
      "\n",
      "    accuracy                           0.74      3170\n",
      "   macro avg       0.75      0.74      0.74      3170\n",
      "weighted avg       0.75      0.74      0.74      3170\n",
      "\n",
      "[[1339  246]\n",
      " [ 574 1011]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10,101):\n",
    "    rfc=RandomForestClassifier(n_estimators=i,random_state=1)\n",
    "    print('No of decision Trees :',i)\n",
    "    rfc=create_model(rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "27363cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.83      0.75      1585\n",
      "           1       0.79      0.62      0.69      1585\n",
      "\n",
      "    accuracy                           0.72      3170\n",
      "   macro avg       0.74      0.72      0.72      3170\n",
      "weighted avg       0.74      0.72      0.72      3170\n",
      "\n",
      "[[1321  264]\n",
      " [ 608  977]]\n"
     ]
    }
   ],
   "source": [
    "#RandomForestClassifier Algorithm\n",
    "#No of decision Trees=17 gives value of recall 0.63 \n",
    "rfc=RandomForestClassifier(n_estimators=17,random_state=1)\n",
    "rfc=create_model(rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d70538a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max depth : 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.69      0.74      1585\n",
      "           1       0.73      0.83      0.78      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.77      0.76      0.76      3170\n",
      "weighted avg       0.77      0.76      0.76      3170\n",
      "\n",
      "[[1096  489]\n",
      " [ 269 1316]]\n",
      "Max depth : 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.72      0.77      1585\n",
      "           1       0.75      0.84      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1143  442]\n",
      " [ 260 1325]]\n",
      "Max depth : 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.72      0.77      1585\n",
      "           1       0.75      0.85      0.80      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.79      0.78      0.78      3170\n",
      "weighted avg       0.79      0.78      0.78      3170\n",
      "\n",
      "[[1136  449]\n",
      " [ 240 1345]]\n",
      "Max depth : 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.72      0.77      1585\n",
      "           1       0.75      0.85      0.80      1585\n",
      "\n",
      "    accuracy                           0.79      3170\n",
      "   macro avg       0.79      0.79      0.79      3170\n",
      "weighted avg       0.79      0.79      0.79      3170\n",
      "\n",
      "[[1141  444]\n",
      " [ 230 1355]]\n",
      "Max depth : 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.72      0.77      1585\n",
      "           1       0.75      0.84      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1147  438]\n",
      " [ 257 1328]]\n",
      "Max depth : 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.77      1585\n",
      "           1       0.75      0.82      0.78      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.77      3170\n",
      "weighted avg       0.78      0.78      0.77      3170\n",
      "\n",
      "[[1160  425]\n",
      " [ 287 1298]]\n",
      "Max depth : 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.74      0.77      1585\n",
      "           1       0.76      0.81      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1177  408]\n",
      " [ 295 1290]]\n",
      "Max depth : 8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.75      0.77      1585\n",
      "           1       0.76      0.79      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1193  392]\n",
      " [ 326 1259]]\n"
     ]
    }
   ],
   "source": [
    "#Apply max_depth pruning on RandomForestClassifier Algorithm\n",
    "for i in range(1,9):\n",
    "    rfc_max_depth=RandomForestClassifier(n_estimators=17,random_state=1,max_depth=i)\n",
    "    print('Max depth :',i)\n",
    "    rfc_max_depth=create_model(rfc_max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "95272ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.72      0.77      1585\n",
      "           1       0.75      0.85      0.80      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.79      0.78      0.78      3170\n",
      "weighted avg       0.79      0.78      0.78      3170\n",
      "\n",
      "[[1136  449]\n",
      " [ 240 1345]]\n"
     ]
    }
   ],
   "source": [
    "#max_depth pruning on RandomForestClassifier Algorithm\n",
    "#Max depth = 3 gives best recall 0.83\n",
    "rfc_max_depth=RandomForestClassifier(n_estimators=17,random_state=1,max_depth=3)\n",
    "rfc_max_depth=create_model(rfc_max_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cf71c671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min_samples_leaf : 45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.75      0.78      1585\n",
      "           1       0.76      0.82      0.79      1585\n",
      "\n",
      "    accuracy                           0.79      3170\n",
      "   macro avg       0.79      0.79      0.78      3170\n",
      "weighted avg       0.79      0.79      0.78      3170\n",
      "\n",
      "[[1184  401]\n",
      " [ 280 1305]]\n",
      "Min_samples_leaf : 46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.74      0.77      1585\n",
      "           1       0.76      0.82      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1170  415]\n",
      " [ 288 1297]]\n",
      "Min_samples_leaf : 47\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76      1585\n",
      "           1       0.75      0.81      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1163  422]\n",
      " [ 298 1287]]\n",
      "Min_samples_leaf : 48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76      1585\n",
      "           1       0.75      0.81      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1161  424]\n",
      " [ 296 1289]]\n",
      "Min_samples_leaf : 49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76      1585\n",
      "           1       0.75      0.82      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1157  428]\n",
      " [ 290 1295]]\n",
      "Min_samples_leaf : 50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.74      0.77      1585\n",
      "           1       0.76      0.81      0.78      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1171  414]\n",
      " [ 294 1291]]\n",
      "Min_samples_leaf : 51\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.74      0.77      1585\n",
      "           1       0.76      0.82      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1175  410]\n",
      " [ 291 1294]]\n",
      "Min_samples_leaf : 52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.74      0.77      1585\n",
      "           1       0.76      0.82      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1173  412]\n",
      " [ 285 1300]]\n",
      "Min_samples_leaf : 53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.75      0.77      1585\n",
      "           1       0.76      0.81      0.78      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1185  400]\n",
      " [ 305 1280]]\n",
      "Min_samples_leaf : 54\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.74      0.77      1585\n",
      "           1       0.76      0.82      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1169  416]\n",
      " [ 286 1299]]\n",
      "Min_samples_leaf : 55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.74      0.77      1585\n",
      "           1       0.76      0.82      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1172  413]\n",
      " [ 278 1307]]\n",
      "Min_samples_leaf : 56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.74      0.78      1585\n",
      "           1       0.76      0.83      0.80      1585\n",
      "\n",
      "    accuracy                           0.79      3170\n",
      "   macro avg       0.79      0.79      0.79      3170\n",
      "weighted avg       0.79      0.79      0.79      3170\n",
      "\n",
      "[[1169  416]\n",
      " [ 262 1323]]\n",
      "Min_samples_leaf : 57\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.74      0.77      1585\n",
      "           1       0.76      0.82      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1180  405]\n",
      " [ 286 1299]]\n",
      "Min_samples_leaf : 58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.74      0.77      1585\n",
      "           1       0.76      0.82      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1178  407]\n",
      " [ 292 1293]]\n",
      "Min_samples_leaf : 59\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.74      0.77      1585\n",
      "           1       0.76      0.83      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.79      0.78      0.78      3170\n",
      "weighted avg       0.79      0.78      0.78      3170\n",
      "\n",
      "[[1169  416]\n",
      " [ 270 1315]]\n",
      "Min_samples_leaf : 60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.75      0.77      1585\n",
      "           1       0.76      0.80      0.78      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1188  397]\n",
      " [ 310 1275]]\n",
      "Min_samples_leaf : 61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.74      0.76      1585\n",
      "           1       0.76      0.80      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1172  413]\n",
      " [ 310 1275]]\n",
      "Min_samples_leaf : 62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.75      0.78      1585\n",
      "           1       0.77      0.82      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.79      0.78      0.78      3170\n",
      "weighted avg       0.79      0.78      0.78      3170\n",
      "\n",
      "[[1188  397]\n",
      " [ 285 1300]]\n",
      "Min_samples_leaf : 63\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.74      0.77      1585\n",
      "           1       0.76      0.81      0.78      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1176  409]\n",
      " [ 298 1287]]\n",
      "Min_samples_leaf : 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.74      0.77      1585\n",
      "           1       0.76      0.82      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1167  418]\n",
      " [ 288 1297]]\n",
      "Min_samples_leaf : 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.74      0.77      1585\n",
      "           1       0.76      0.82      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1170  415]\n",
      " [ 287 1298]]\n",
      "Min_samples_leaf : 66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.74      0.77      1585\n",
      "           1       0.76      0.82      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1176  409]\n",
      " [ 287 1298]]\n",
      "Min_samples_leaf : 67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.74      0.77      1585\n",
      "           1       0.76      0.83      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1169  416]\n",
      " [ 277 1308]]\n",
      "Min_samples_leaf : 68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.74      0.77      1585\n",
      "           1       0.76      0.83      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.79      0.78      0.78      3170\n",
      "weighted avg       0.79      0.78      0.78      3170\n",
      "\n",
      "[[1172  413]\n",
      " [ 271 1314]]\n",
      "Min_samples_leaf : 69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.73      0.77      1585\n",
      "           1       0.75      0.83      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1150  435]\n",
      " [ 266 1319]]\n",
      "Min_samples_leaf : 70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.73      0.77      1585\n",
      "           1       0.75      0.84      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.79      0.78      0.78      3170\n",
      "weighted avg       0.79      0.78      0.78      3170\n",
      "\n",
      "[[1151  434]\n",
      " [ 253 1332]]\n",
      "Min_samples_leaf : 71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.73      0.77      1585\n",
      "           1       0.76      0.83      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1158  427]\n",
      " [ 266 1319]]\n",
      "Min_samples_leaf : 72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.73      0.77      1585\n",
      "           1       0.76      0.84      0.80      1585\n",
      "\n",
      "    accuracy                           0.79      3170\n",
      "   macro avg       0.79      0.79      0.78      3170\n",
      "weighted avg       0.79      0.79      0.78      3170\n",
      "\n",
      "[[1164  421]\n",
      " [ 259 1326]]\n",
      "Min_samples_leaf : 73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.75      0.78      1585\n",
      "           1       0.77      0.83      0.80      1585\n",
      "\n",
      "    accuracy                           0.79      3170\n",
      "   macro avg       0.79      0.79      0.79      3170\n",
      "weighted avg       0.79      0.79      0.79      3170\n",
      "\n",
      "[[1182  403]\n",
      " [ 270 1315]]\n",
      "Min_samples_leaf : 74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.75      0.77      1585\n",
      "           1       0.77      0.81      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1189  396]\n",
      " [ 295 1290]]\n",
      "Min_samples_leaf : 75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.75      0.77      1585\n",
      "           1       0.77      0.81      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1191  394]\n",
      " [ 299 1286]]\n",
      "Min_samples_leaf : 76\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.74      0.77      1585\n",
      "           1       0.76      0.81      0.78      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1179  406]\n",
      " [ 299 1286]]\n",
      "Min_samples_leaf : 77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.75      0.78      1585\n",
      "           1       0.77      0.82      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.79      0.78      0.78      3170\n",
      "weighted avg       0.79      0.78      0.78      3170\n",
      "\n",
      "[[1189  396]\n",
      " [ 286 1299]]\n",
      "Min_samples_leaf : 78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.74      0.78      1585\n",
      "           1       0.76      0.83      0.79      1585\n",
      "\n",
      "    accuracy                           0.79      3170\n",
      "   macro avg       0.79      0.79      0.79      3170\n",
      "weighted avg       0.79      0.79      0.79      3170\n",
      "\n",
      "[[1178  407]\n",
      " [ 273 1312]]\n",
      "Min_samples_leaf : 79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.74      0.77      1585\n",
      "           1       0.76      0.82      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1175  410]\n",
      " [ 283 1302]]\n",
      "Min_samples_leaf : 80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.74      0.77      1585\n",
      "           1       0.76      0.82      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1170  415]\n",
      " [ 281 1304]]\n",
      "Min_samples_leaf : 81\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.77      1585\n",
      "           1       0.75      0.82      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1159  426]\n",
      " [ 282 1303]]\n",
      "Min_samples_leaf : 82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.73      0.77      1585\n",
      "           1       0.75      0.83      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1155  430]\n",
      " [ 267 1318]]\n",
      "Min_samples_leaf : 83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.73      0.77      1585\n",
      "           1       0.75      0.83      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1155  430]\n",
      " [ 271 1314]]\n",
      "Min_samples_leaf : 84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76      1585\n",
      "           1       0.75      0.82      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1157  428]\n",
      " [ 290 1295]]\n",
      "Min_samples_leaf : 85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.74      0.77      1585\n",
      "           1       0.76      0.82      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1167  418]\n",
      " [ 284 1301]]\n",
      "Min_samples_leaf : 86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.74      0.77      1585\n",
      "           1       0.76      0.81      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1177  408]\n",
      " [ 295 1290]]\n",
      "Min_samples_leaf : 87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.75      0.77      1585\n",
      "           1       0.76      0.80      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1183  402]\n",
      " [ 316 1269]]\n",
      "Min_samples_leaf : 88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.76      0.77      1585\n",
      "           1       0.76      0.80      0.78      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1197  388]\n",
      " [ 322 1263]]\n",
      "Min_samples_leaf : 89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.74      0.77      1585\n",
      "           1       0.76      0.82      0.78      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1170  415]\n",
      " [ 293 1292]]\n",
      "Min_samples_leaf : 90\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.75      0.77      1585\n",
      "           1       0.76      0.80      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1181  404]\n",
      " [ 312 1273]]\n",
      "Min_samples_leaf : 91\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.74      0.77      1585\n",
      "           1       0.76      0.82      0.78      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1167  418]\n",
      " [ 292 1293]]\n",
      "Min_samples_leaf : 92\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.75      0.77      1585\n",
      "           1       0.76      0.80      0.78      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.77      3170\n",
      "weighted avg       0.78      0.78      0.77      3170\n",
      "\n",
      "[[1187  398]\n",
      " [ 315 1270]]\n",
      "Min_samples_leaf : 93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.74      0.77      1585\n",
      "           1       0.75      0.81      0.78      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.77      3170\n",
      "weighted avg       0.78      0.78      0.77      3170\n",
      "\n",
      "[[1166  419]\n",
      " [ 294 1291]]\n",
      "Min_samples_leaf : 94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.77      1585\n",
      "           1       0.75      0.82      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1158  427]\n",
      " [ 281 1304]]\n",
      "Min_samples_leaf : 95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.75      0.77      1585\n",
      "           1       0.76      0.81      0.78      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1181  404]\n",
      " [ 300 1285]]\n",
      "Min_samples_leaf : 96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.74      0.77      1585\n",
      "           1       0.76      0.81      0.78      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1178  407]\n",
      " [ 299 1286]]\n",
      "Min_samples_leaf : 97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.73      0.77      1585\n",
      "           1       0.76      0.83      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1160  425]\n",
      " [ 266 1319]]\n",
      "Min_samples_leaf : 98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.73      0.77      1585\n",
      "           1       0.76      0.84      0.80      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.79      0.78      0.78      3170\n",
      "weighted avg       0.79      0.78      0.78      3170\n",
      "\n",
      "[[1160  425]\n",
      " [ 257 1328]]\n",
      "Min_samples_leaf : 99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.73      0.77      1585\n",
      "           1       0.76      0.84      0.80      1585\n",
      "\n",
      "    accuracy                           0.79      3170\n",
      "   macro avg       0.79      0.79      0.78      3170\n",
      "weighted avg       0.79      0.79      0.78      3170\n",
      "\n",
      "[[1162  423]\n",
      " [ 257 1328]]\n",
      "Min_samples_leaf : 100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.73      0.77      1585\n",
      "           1       0.76      0.84      0.80      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.79      0.78      0.78      3170\n",
      "weighted avg       0.79      0.78      0.78      3170\n",
      "\n",
      "[[1162  423]\n",
      " [ 260 1325]]\n"
     ]
    }
   ],
   "source": [
    "#Apply min_samples_leaf pruning on RandomForestClassifier Algorithm\n",
    "for i in range(45,101):\n",
    "    rfc_min_leaf=RandomForestClassifier(n_estimators=17,random_state=1,min_samples_leaf=i)\n",
    "    print('Min_samples_leaf :',i)\n",
    "    rfc_min_leaf=create_model(rfc_min_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9ff0c8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.74      0.77      1585\n",
      "           1       0.76      0.82      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1173  412]\n",
      " [ 285 1300]]\n"
     ]
    }
   ],
   "source": [
    "#min_samples_leaf pruning on RandomForestClassifier Algorithm\n",
    "#min_samples_leaf = 52 gives best recall 0.81\n",
    "rfc_min_leaf=RandomForestClassifier(n_estimators=17,random_state=1,min_samples_leaf=52)\n",
    "rfc_min_leaf=create_model(rfc_min_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1267d0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply ADABoostClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "33edb624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Decision stumps: 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.58      0.70      1585\n",
      "           1       0.68      0.92      0.78      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.78      0.75      0.74      3170\n",
      "weighted avg       0.78      0.75      0.74      3170\n",
      "\n",
      "[[ 916  669]\n",
      " [ 132 1453]]\n",
      "No of Decision stumps: 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.58      0.70      1585\n",
      "           1       0.68      0.92      0.78      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.78      0.75      0.74      3170\n",
      "weighted avg       0.78      0.75      0.74      3170\n",
      "\n",
      "[[ 916  669]\n",
      " [ 132 1453]]\n",
      "No of Decision stumps: 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.71      0.75      1585\n",
      "           1       0.74      0.83      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1118  467]\n",
      " [ 267 1318]]\n",
      "No of Decision stumps: 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.67      0.75      1585\n",
      "           1       0.73      0.87      0.79      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.79      0.77      0.77      3170\n",
      "weighted avg       0.79      0.77      0.77      3170\n",
      "\n",
      "[[1068  517]\n",
      " [ 200 1385]]\n",
      "No of Decision stumps: 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.67      0.75      1585\n",
      "           1       0.73      0.87      0.79      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.79      0.77      0.77      3170\n",
      "weighted avg       0.79      0.77      0.77      3170\n",
      "\n",
      "[[1069  516]\n",
      " [ 200 1385]]\n",
      "No of Decision stumps: 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.67      0.75      1585\n",
      "           1       0.73      0.87      0.79      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.79      0.77      0.77      3170\n",
      "weighted avg       0.79      0.77      0.77      3170\n",
      "\n",
      "[[1068  517]\n",
      " [ 200 1385]]\n",
      "No of Decision stumps: 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.67      0.75      1585\n",
      "           1       0.73      0.87      0.79      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.79      0.77      0.77      3170\n",
      "weighted avg       0.79      0.77      0.77      3170\n",
      "\n",
      "[[1069  516]\n",
      " [ 200 1385]]\n",
      "No of Decision stumps: 8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.67      0.75      1585\n",
      "           1       0.73      0.87      0.79      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.79      0.77      0.77      3170\n",
      "weighted avg       0.79      0.77      0.77      3170\n",
      "\n",
      "[[1068  517]\n",
      " [ 200 1385]]\n",
      "No of Decision stumps: 9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.70      0.76      1585\n",
      "           1       0.74      0.85      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.77      3170\n",
      "weighted avg       0.78      0.78      0.77      3170\n",
      "\n",
      "[[1115  470]\n",
      " [ 242 1343]]\n",
      "No of Decision stumps: 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.70      0.76      1585\n",
      "           1       0.74      0.85      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.77      3170\n",
      "weighted avg       0.78      0.78      0.77      3170\n",
      "\n",
      "[[1116  469]\n",
      " [ 242 1343]]\n",
      "No of Decision stumps: 11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.67      0.75      1585\n",
      "           1       0.73      0.88      0.79      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.79      0.77      0.77      3170\n",
      "weighted avg       0.79      0.77      0.77      3170\n",
      "\n",
      "[[1066  519]\n",
      " [ 197 1388]]\n",
      "No of Decision stumps: 12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.67      0.75      1585\n",
      "           1       0.73      0.88      0.79      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.79      0.77      0.77      3170\n",
      "weighted avg       0.79      0.77      0.77      3170\n",
      "\n",
      "[[1066  519]\n",
      " [ 197 1388]]\n",
      "No of Decision stumps: 13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.70      0.76      1585\n",
      "           1       0.74      0.85      0.79      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1105  480]\n",
      " [ 236 1349]]\n",
      "No of Decision stumps: 14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.70      0.76      1585\n",
      "           1       0.74      0.86      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.79      0.78      0.78      3170\n",
      "weighted avg       0.79      0.78      0.78      3170\n",
      "\n",
      "[[1103  482]\n",
      " [ 223 1362]]\n",
      "No of Decision stumps: 15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.71      0.76      1585\n",
      "           1       0.75      0.84      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1130  455]\n",
      " [ 253 1332]]\n",
      "No of Decision stumps: 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.71      0.76      1585\n",
      "           1       0.74      0.85      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1118  467]\n",
      " [ 240 1345]]\n",
      "No of Decision stumps: 17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.71      0.76      1585\n",
      "           1       0.75      0.84      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1129  456]\n",
      " [ 252 1333]]\n",
      "No of Decision stumps: 18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.71      0.76      1585\n",
      "           1       0.75      0.84      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1129  456]\n",
      " [ 252 1333]]\n",
      "No of Decision stumps: 19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.71      0.76      1585\n",
      "           1       0.74      0.85      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1121  464]\n",
      " [ 237 1348]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,20):\n",
    "    abc=AdaBoostClassifier(n_estimators=i,random_state=1)\n",
    "    print('No of Decision stumps:',i)\n",
    "    abc=create_model(abc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2987fefe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.67      0.75      1585\n",
      "           1       0.73      0.87      0.79      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.79      0.77      0.77      3170\n",
      "weighted avg       0.79      0.77      0.77      3170\n",
      "\n",
      "[[1068  517]\n",
      " [ 200 1385]]\n"
     ]
    }
   ],
   "source": [
    "#ADABoostClassifier\n",
    "#No of decision stump=6 gives best recall 0.85\n",
    "abc=AdaBoostClassifier(n_estimators=6,random_state=1)\n",
    "abc=create_model(abc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "08f26c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply GradientBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8aabf70f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of decision tree: 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.69      0.75      1585\n",
      "           1       0.73      0.86      0.79      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1090  495]\n",
      " [ 227 1358]]\n",
      "No of decision tree: 11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.70      0.76      1585\n",
      "           1       0.74      0.86      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.77      3170\n",
      "weighted avg       0.78      0.78      0.77      3170\n",
      "\n",
      "[[1105  480]\n",
      " [ 229 1356]]\n",
      "No of decision tree: 12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.73      0.76      1585\n",
      "           1       0.75      0.81      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1152  433]\n",
      " [ 305 1280]]\n",
      "No of decision tree: 13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.71      0.76      1585\n",
      "           1       0.74      0.83      0.79      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1126  459]\n",
      " [ 264 1321]]\n",
      "No of decision tree: 14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.71      0.76      1585\n",
      "           1       0.74      0.84      0.79      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1126  459]\n",
      " [ 259 1326]]\n",
      "No of decision tree: 15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.71      0.76      1585\n",
      "           1       0.74      0.83      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1133  452]\n",
      " [ 269 1316]]\n",
      "No of decision tree: 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.71      0.76      1585\n",
      "           1       0.74      0.83      0.79      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1126  459]\n",
      " [ 264 1321]]\n",
      "No of decision tree: 17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.71      0.76      1585\n",
      "           1       0.74      0.83      0.79      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1130  455]\n",
      " [ 264 1321]]\n",
      "No of decision tree: 18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.71      0.76      1585\n",
      "           1       0.74      0.83      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1132  453]\n",
      " [ 269 1316]]\n",
      "No of decision tree: 19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.72      0.76      1585\n",
      "           1       0.75      0.83      0.79      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1134  451]\n",
      " [ 267 1318]]\n",
      "No of decision tree: 20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.71      0.76      1585\n",
      "           1       0.74      0.84      0.79      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1131  454]\n",
      " [ 260 1325]]\n",
      "No of decision tree: 21\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.72      0.76      1585\n",
      "           1       0.75      0.83      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.77      3170\n",
      "weighted avg       0.78      0.78      0.77      3170\n",
      "\n",
      "[[1142  443]\n",
      " [ 269 1316]]\n",
      "No of decision tree: 22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.72      0.76      1585\n",
      "           1       0.75      0.84      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1137  448]\n",
      " [ 260 1325]]\n",
      "No of decision tree: 23\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.71      0.76      1585\n",
      "           1       0.74      0.83      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1132  453]\n",
      " [ 274 1311]]\n",
      "No of decision tree: 24\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.71      0.76      1585\n",
      "           1       0.74      0.82      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1133  452]\n",
      " [ 282 1303]]\n",
      "No of decision tree: 25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.72      0.76      1585\n",
      "           1       0.74      0.82      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1136  449]\n",
      " [ 284 1301]]\n",
      "No of decision tree: 26\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.72      0.76      1585\n",
      "           1       0.74      0.83      0.79      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1134  451]\n",
      " [ 268 1317]]\n",
      "No of decision tree: 27\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.72      0.76      1585\n",
      "           1       0.74      0.83      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1135  450]\n",
      " [ 275 1310]]\n",
      "No of decision tree: 28\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.72      0.76      1585\n",
      "           1       0.75      0.83      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1137  448]\n",
      " [ 273 1312]]\n",
      "No of decision tree: 29\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.72      0.76      1585\n",
      "           1       0.75      0.83      0.79      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1139  446]\n",
      " [ 272 1313]]\n",
      "No of decision tree: 30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.72      0.76      1585\n",
      "           1       0.75      0.83      0.79      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1139  446]\n",
      " [ 272 1313]]\n",
      "No of decision tree: 31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.72      0.76      1585\n",
      "           1       0.75      0.83      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.77      3170\n",
      "weighted avg       0.78      0.78      0.77      3170\n",
      "\n",
      "[[1140  445]\n",
      " [ 266 1319]]\n",
      "No of decision tree: 32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.72      0.76      1585\n",
      "           1       0.75      0.83      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1142  443]\n",
      " [ 266 1319]]\n",
      "No of decision tree: 33\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.72      0.76      1585\n",
      "           1       0.75      0.83      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1144  441]\n",
      " [ 264 1321]]\n",
      "No of decision tree: 34\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.72      0.76      1585\n",
      "           1       0.75      0.83      0.79      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1141  444]\n",
      " [ 271 1314]]\n",
      "No of decision tree: 35\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.72      0.76      1585\n",
      "           1       0.75      0.83      0.79      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1145  440]\n",
      " [ 276 1309]]\n",
      "No of decision tree: 36\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.72      0.76      1585\n",
      "           1       0.75      0.83      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.77      3170\n",
      "weighted avg       0.78      0.78      0.77      3170\n",
      "\n",
      "[[1144  441]\n",
      " [ 272 1313]]\n",
      "No of decision tree: 37\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.72      0.76      1585\n",
      "           1       0.75      0.83      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1142  443]\n",
      " [ 265 1320]]\n",
      "No of decision tree: 38\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.72      0.76      1585\n",
      "           1       0.75      0.83      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1142  443]\n",
      " [ 262 1323]]\n",
      "No of decision tree: 39\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.72      0.76      1585\n",
      "           1       0.75      0.83      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.77      3170\n",
      "weighted avg       0.78      0.78      0.77      3170\n",
      "\n",
      "[[1143  442]\n",
      " [ 271 1314]]\n",
      "No of decision tree: 40\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.72      0.76      1585\n",
      "           1       0.75      0.83      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1145  440]\n",
      " [ 267 1318]]\n",
      "No of decision tree: 41\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.72      0.76      1585\n",
      "           1       0.75      0.83      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1145  440]\n",
      " [ 267 1318]]\n",
      "No of decision tree: 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.72      0.77      1585\n",
      "           1       0.75      0.83      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1146  439]\n",
      " [ 263 1322]]\n",
      "No of decision tree: 43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.72      0.76      1585\n",
      "           1       0.75      0.83      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1144  441]\n",
      " [ 266 1319]]\n",
      "No of decision tree: 44\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.72      0.76      1585\n",
      "           1       0.75      0.83      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1146  439]\n",
      " [ 266 1319]]\n",
      "No of decision tree: 45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.73      0.77      1585\n",
      "           1       0.75      0.83      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1150  435]\n",
      " [ 266 1319]]\n",
      "No of decision tree: 46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.72      0.77      1585\n",
      "           1       0.75      0.84      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1149  436]\n",
      " [ 260 1325]]\n",
      "No of decision tree: 47\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.72      0.77      1585\n",
      "           1       0.75      0.84      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1148  437]\n",
      " [ 260 1325]]\n",
      "No of decision tree: 48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.72      0.77      1585\n",
      "           1       0.75      0.84      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.79      0.78      0.78      3170\n",
      "weighted avg       0.79      0.78      0.78      3170\n",
      "\n",
      "[[1148  437]\n",
      " [ 255 1330]]\n",
      "No of decision tree: 49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.72      0.77      1585\n",
      "           1       0.75      0.84      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.79      0.78      0.78      3170\n",
      "weighted avg       0.79      0.78      0.78      3170\n",
      "\n",
      "[[1148  437]\n",
      " [ 255 1330]]\n",
      "No of decision tree: 50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.72      0.77      1585\n",
      "           1       0.75      0.84      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1148  437]\n",
      " [ 261 1324]]\n",
      "No of decision tree: 51\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.73      0.77      1585\n",
      "           1       0.75      0.83      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1152  433]\n",
      " [ 263 1322]]\n",
      "No of decision tree: 52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.73      0.77      1585\n",
      "           1       0.75      0.83      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1152  433]\n",
      " [ 263 1322]]\n",
      "No of decision tree: 53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.73      0.77      1585\n",
      "           1       0.75      0.83      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1152  433]\n",
      " [ 267 1318]]\n",
      "No of decision tree: 54\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.73      0.77      1585\n",
      "           1       0.75      0.83      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1152  433]\n",
      " [ 267 1318]]\n",
      "No of decision tree: 55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.73      0.77      1585\n",
      "           1       0.75      0.83      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1155  430]\n",
      " [ 266 1319]]\n",
      "No of decision tree: 56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.73      0.77      1585\n",
      "           1       0.75      0.83      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1155  430]\n",
      " [ 266 1319]]\n",
      "No of decision tree: 57\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.73      0.77      1585\n",
      "           1       0.75      0.83      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1155  430]\n",
      " [ 266 1319]]\n",
      "No of decision tree: 58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.73      0.77      1585\n",
      "           1       0.75      0.83      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1153  432]\n",
      " [ 263 1322]]\n",
      "No of decision tree: 59\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.73      0.77      1585\n",
      "           1       0.75      0.83      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1152  433]\n",
      " [ 266 1319]]\n",
      "No of decision tree: 60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.73      0.77      1585\n",
      "           1       0.75      0.83      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1153  432]\n",
      " [ 264 1321]]\n",
      "No of decision tree: 61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.73      0.77      1585\n",
      "           1       0.75      0.83      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1154  431]\n",
      " [ 269 1316]]\n",
      "No of decision tree: 62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.73      0.77      1585\n",
      "           1       0.75      0.83      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1154  431]\n",
      " [ 272 1313]]\n",
      "No of decision tree: 63\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.73      0.77      1585\n",
      "           1       0.75      0.83      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1154  431]\n",
      " [ 272 1313]]\n",
      "No of decision tree: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.73      0.77      1585\n",
      "           1       0.75      0.83      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1154  431]\n",
      " [ 272 1313]]\n",
      "No of decision tree: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.73      0.77      1585\n",
      "           1       0.75      0.83      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1153  432]\n",
      " [ 269 1316]]\n",
      "No of decision tree: 66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.73      0.77      1585\n",
      "           1       0.75      0.83      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1155  430]\n",
      " [ 273 1312]]\n",
      "No of decision tree: 67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.73      0.77      1585\n",
      "           1       0.75      0.82      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1155  430]\n",
      " [ 279 1306]]\n",
      "No of decision tree: 68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76      1585\n",
      "           1       0.75      0.82      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1153  432]\n",
      " [ 282 1303]]\n",
      "No of decision tree: 69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76      1585\n",
      "           1       0.75      0.82      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1153  432]\n",
      " [ 282 1303]]\n",
      "No of decision tree: 70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.73      0.76      1585\n",
      "           1       0.75      0.82      0.79      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1153  432]\n",
      " [ 278 1307]]\n",
      "No of decision tree: 71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76      1585\n",
      "           1       0.75      0.82      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1153  432]\n",
      " [ 282 1303]]\n",
      "No of decision tree: 72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76      1585\n",
      "           1       0.75      0.82      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1153  432]\n",
      " [ 287 1298]]\n",
      "No of decision tree: 73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76      1585\n",
      "           1       0.75      0.82      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1153  432]\n",
      " [ 287 1298]]\n",
      "No of decision tree: 74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76      1585\n",
      "           1       0.75      0.82      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1154  431]\n",
      " [ 290 1295]]\n",
      "No of decision tree: 75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76      1585\n",
      "           1       0.75      0.82      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1154  431]\n",
      " [ 283 1302]]\n",
      "No of decision tree: 76\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76      1585\n",
      "           1       0.75      0.82      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1153  432]\n",
      " [ 290 1295]]\n",
      "No of decision tree: 77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76      1585\n",
      "           1       0.75      0.82      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1154  431]\n",
      " [ 287 1298]]\n",
      "No of decision tree: 78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76      1585\n",
      "           1       0.75      0.82      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1154  431]\n",
      " [ 287 1298]]\n",
      "No of decision tree: 79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76      1585\n",
      "           1       0.75      0.82      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1155  430]\n",
      " [ 293 1292]]\n",
      "No of decision tree: 80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76      1585\n",
      "           1       0.75      0.82      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1155  430]\n",
      " [ 293 1292]]\n",
      "No of decision tree: 81\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76      1585\n",
      "           1       0.75      0.82      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1157  428]\n",
      " [ 293 1292]]\n",
      "No of decision tree: 82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76      1585\n",
      "           1       0.75      0.81      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1158  427]\n",
      " [ 297 1288]]\n",
      "No of decision tree: 83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76      1585\n",
      "           1       0.75      0.81      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1160  425]\n",
      " [ 297 1288]]\n",
      "No of decision tree: 84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76      1585\n",
      "           1       0.75      0.81      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1161  424]\n",
      " [ 295 1290]]\n",
      "No of decision tree: 85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76      1585\n",
      "           1       0.75      0.81      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1158  427]\n",
      " [ 297 1288]]\n",
      "No of decision tree: 86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76      1585\n",
      "           1       0.75      0.81      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1159  426]\n",
      " [ 297 1288]]\n",
      "No of decision tree: 87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76      1585\n",
      "           1       0.75      0.81      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1160  425]\n",
      " [ 297 1288]]\n",
      "No of decision tree: 88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76      1585\n",
      "           1       0.75      0.81      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1161  424]\n",
      " [ 295 1290]]\n",
      "No of decision tree: 89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76      1585\n",
      "           1       0.75      0.81      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1161  424]\n",
      " [ 295 1290]]\n",
      "No of decision tree: 90\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76      1585\n",
      "           1       0.75      0.81      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1162  423]\n",
      " [ 299 1286]]\n",
      "No of decision tree: 91\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.73      0.76      1585\n",
      "           1       0.75      0.81      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1162  423]\n",
      " [ 307 1278]]\n",
      "No of decision tree: 92\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.73      0.76      1585\n",
      "           1       0.75      0.81      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1161  424]\n",
      " [ 307 1278]]\n",
      "No of decision tree: 93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.73      0.76      1585\n",
      "           1       0.75      0.81      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1162  423]\n",
      " [ 307 1278]]\n",
      "No of decision tree: 94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.73      0.76      1585\n",
      "           1       0.75      0.81      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1162  423]\n",
      " [ 307 1278]]\n",
      "No of decision tree: 95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.73      0.76      1585\n",
      "           1       0.75      0.81      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1161  424]\n",
      " [ 307 1278]]\n",
      "No of decision tree: 96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.73      0.76      1585\n",
      "           1       0.75      0.81      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1163  422]\n",
      " [ 307 1278]]\n",
      "No of decision tree: 97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.73      0.76      1585\n",
      "           1       0.75      0.81      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1161  424]\n",
      " [ 301 1284]]\n",
      "No of decision tree: 98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76      1585\n",
      "           1       0.75      0.81      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1161  424]\n",
      " [ 298 1287]]\n",
      "No of decision tree: 99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76      1585\n",
      "           1       0.75      0.81      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1162  423]\n",
      " [ 298 1287]]\n",
      "No of decision tree: 100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76      1585\n",
      "           1       0.75      0.81      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1162  423]\n",
      " [ 298 1287]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10,101):\n",
    "    gbc=GradientBoostingClassifier(n_estimators=i,random_state=1)\n",
    "    print('No of decision tree:',i)\n",
    "    gbc=create_model(gbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2b789006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.73      0.76      1585\n",
      "           1       0.75      0.81      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1152  433]\n",
      " [ 305 1280]]\n"
     ]
    }
   ],
   "source": [
    "#GradientBoostingClassifier\n",
    "#Number of Decision Tree=12\n",
    "gbc=GradientBoostingClassifier(n_estimators=12,random_state=1)\n",
    "gbc=create_model(gbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c3ecd04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply XtremeGradientBoostClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fb67c317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of decision tree: 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.75      0.77      1585\n",
      "           1       0.76      0.80      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.78      0.77      0.77      3170\n",
      "weighted avg       0.78      0.77      0.77      3170\n",
      "\n",
      "[[1187  398]\n",
      " [ 317 1268]]\n",
      "No of decision tree: 11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.75      0.77      1585\n",
      "           1       0.76      0.80      0.78      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1191  394]\n",
      " [ 316 1269]]\n",
      "No of decision tree: 12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.75      0.77      1585\n",
      "           1       0.76      0.80      0.78      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1193  392]\n",
      " [ 315 1270]]\n",
      "No of decision tree: 13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.76      0.77      1585\n",
      "           1       0.76      0.79      0.78      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.77      3170\n",
      "weighted avg       0.78      0.78      0.77      3170\n",
      "\n",
      "[[1198  387]\n",
      " [ 326 1259]]\n",
      "No of decision tree: 14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.76      0.77      1585\n",
      "           1       0.76      0.79      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1200  385]\n",
      " [ 337 1248]]\n",
      "No of decision tree: 15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.76      0.77      1585\n",
      "           1       0.77      0.79      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1203  382]\n",
      " [ 337 1248]]\n",
      "No of decision tree: 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.76      0.77      1585\n",
      "           1       0.76      0.79      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1201  384]\n",
      " [ 338 1247]]\n",
      "No of decision tree: 17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.76      0.77      1585\n",
      "           1       0.76      0.79      0.78      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1201  384]\n",
      " [ 338 1247]]\n",
      "No of decision tree: 18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.76      0.77      1585\n",
      "           1       0.76      0.78      0.77      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1203  382]\n",
      " [ 348 1237]]\n",
      "No of decision tree: 19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.76      0.77      1585\n",
      "           1       0.76      0.78      0.77      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1204  381]\n",
      " [ 351 1234]]\n",
      "No of decision tree: 20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.76      0.77      1585\n",
      "           1       0.76      0.78      0.77      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1205  380]\n",
      " [ 351 1234]]\n",
      "No of decision tree: 21\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.76      0.77      1585\n",
      "           1       0.76      0.78      0.77      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1203  382]\n",
      " [ 351 1234]]\n",
      "No of decision tree: 22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.76      0.77      1585\n",
      "           1       0.76      0.77      0.77      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1204  381]\n",
      " [ 358 1227]]\n",
      "No of decision tree: 23\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.76      0.76      1585\n",
      "           1       0.76      0.77      0.77      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.76      0.76      0.76      3170\n",
      "weighted avg       0.76      0.76      0.76      3170\n",
      "\n",
      "[[1203  382]\n",
      " [ 364 1221]]\n",
      "No of decision tree: 24\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.76      0.76      1585\n",
      "           1       0.76      0.77      0.76      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.76      0.76      0.76      3170\n",
      "weighted avg       0.76      0.76      0.76      3170\n",
      "\n",
      "[[1204  381]\n",
      " [ 370 1215]]\n",
      "No of decision tree: 25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.76      0.76      1585\n",
      "           1       0.76      0.77      0.76      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.76      0.76      0.76      3170\n",
      "weighted avg       0.76      0.76      0.76      3170\n",
      "\n",
      "[[1206  379]\n",
      " [ 369 1216]]\n",
      "No of decision tree: 26\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.76      1585\n",
      "           1       0.76      0.76      0.76      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.76      0.76      0.76      3170\n",
      "weighted avg       0.76      0.76      0.76      3170\n",
      "\n",
      "[[1213  372]\n",
      " [ 377 1208]]\n",
      "No of decision tree: 27\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.76      1585\n",
      "           1       0.76      0.76      0.76      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.76      0.76      0.76      3170\n",
      "weighted avg       0.76      0.76      0.76      3170\n",
      "\n",
      "[[1213  372]\n",
      " [ 380 1205]]\n",
      "No of decision tree: 28\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.76      0.76      1585\n",
      "           1       0.76      0.76      0.76      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.76      0.76      0.76      3170\n",
      "weighted avg       0.76      0.76      0.76      3170\n",
      "\n",
      "[[1209  376]\n",
      " [ 376 1209]]\n",
      "No of decision tree: 29\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.76      0.76      1585\n",
      "           1       0.76      0.76      0.76      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.76      0.76      0.76      3170\n",
      "weighted avg       0.76      0.76      0.76      3170\n",
      "\n",
      "[[1207  378]\n",
      " [ 376 1209]]\n",
      "No of decision tree: 30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.76      0.76      1585\n",
      "           1       0.76      0.76      0.76      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.76      0.76      0.76      3170\n",
      "weighted avg       0.76      0.76      0.76      3170\n",
      "\n",
      "[[1211  374]\n",
      " [ 378 1207]]\n",
      "No of decision tree: 31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.76      1585\n",
      "           1       0.76      0.76      0.76      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.76      0.76      0.76      3170\n",
      "weighted avg       0.76      0.76      0.76      3170\n",
      "\n",
      "[[1213  372]\n",
      " [ 378 1207]]\n",
      "No of decision tree: 32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.76      1585\n",
      "           1       0.77      0.76      0.76      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.76      0.76      0.76      3170\n",
      "weighted avg       0.76      0.76      0.76      3170\n",
      "\n",
      "[[1214  371]\n",
      " [ 376 1209]]\n",
      "No of decision tree: 33\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.76      1585\n",
      "           1       0.76      0.75      0.76      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.76      0.76      0.76      3170\n",
      "weighted avg       0.76      0.76      0.76      3170\n",
      "\n",
      "[[1215  370]\n",
      " [ 391 1194]]\n",
      "No of decision tree: 34\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.76      1585\n",
      "           1       0.77      0.76      0.76      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.76      0.76      0.76      3170\n",
      "weighted avg       0.76      0.76      0.76      3170\n",
      "\n",
      "[[1220  365]\n",
      " [ 388 1197]]\n",
      "No of decision tree: 35\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.76      1585\n",
      "           1       0.77      0.76      0.76      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.76      0.76      0.76      3170\n",
      "weighted avg       0.76      0.76      0.76      3170\n",
      "\n",
      "[[1221  364]\n",
      " [ 388 1197]]\n",
      "No of decision tree: 36\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.76      1585\n",
      "           1       0.77      0.75      0.76      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.76      0.76      0.76      3170\n",
      "weighted avg       0.76      0.76      0.76      3170\n",
      "\n",
      "[[1222  363]\n",
      " [ 389 1196]]\n",
      "No of decision tree: 37\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.77      1585\n",
      "           1       0.77      0.75      0.76      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.76      0.76      0.76      3170\n",
      "weighted avg       0.76      0.76      0.76      3170\n",
      "\n",
      "[[1223  362]\n",
      " [ 389 1196]]\n",
      "No of decision tree: 38\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.77      1585\n",
      "           1       0.77      0.75      0.76      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.76      0.76      0.76      3170\n",
      "weighted avg       0.76      0.76      0.76      3170\n",
      "\n",
      "[[1224  361]\n",
      " [ 389 1196]]\n",
      "No of decision tree: 39\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.77      1585\n",
      "           1       0.77      0.75      0.76      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.76      0.76      0.76      3170\n",
      "weighted avg       0.76      0.76      0.76      3170\n",
      "\n",
      "[[1226  359]\n",
      " [ 389 1196]]\n",
      "No of decision tree: 40\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.77      1585\n",
      "           1       0.77      0.76      0.76      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1228  357]\n",
      " [ 385 1200]]\n",
      "No of decision tree: 41\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.78      0.77      1585\n",
      "           1       0.77      0.76      0.76      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1229  356]\n",
      " [ 385 1200]]\n",
      "No of decision tree: 42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.78      0.77      1585\n",
      "           1       0.77      0.76      0.77      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1230  355]\n",
      " [ 377 1208]]\n",
      "No of decision tree: 43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.77      0.77      1585\n",
      "           1       0.77      0.77      0.77      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1224  361]\n",
      " [ 372 1213]]\n",
      "No of decision tree: 44\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.77      1585\n",
      "           1       0.77      0.76      0.77      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1227  358]\n",
      " [ 380 1205]]\n",
      "No of decision tree: 45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.77      1585\n",
      "           1       0.77      0.76      0.76      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1227  358]\n",
      " [ 383 1202]]\n",
      "No of decision tree: 46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.77      1585\n",
      "           1       0.77      0.76      0.76      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.76      0.76      0.76      3170\n",
      "weighted avg       0.76      0.76      0.76      3170\n",
      "\n",
      "[[1222  363]\n",
      " [ 383 1202]]\n",
      "No of decision tree: 47\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.77      1585\n",
      "           1       0.77      0.76      0.76      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1224  361]\n",
      " [ 383 1202]]\n",
      "No of decision tree: 48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.77      1585\n",
      "           1       0.77      0.76      0.76      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1224  361]\n",
      " [ 381 1204]]\n",
      "No of decision tree: 49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.77      1585\n",
      "           1       0.77      0.75      0.76      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.76      0.76      0.76      3170\n",
      "weighted avg       0.76      0.76      0.76      3170\n",
      "\n",
      "[[1225  360]\n",
      " [ 392 1193]]\n",
      "No of decision tree: 50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.76      1585\n",
      "           1       0.77      0.75      0.76      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.76      0.76      0.76      3170\n",
      "weighted avg       0.76      0.76      0.76      3170\n",
      "\n",
      "[[1227  358]\n",
      " [ 397 1188]]\n",
      "No of decision tree: 51\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76      1585\n",
      "           1       0.77      0.75      0.76      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.76      0.76      0.76      3170\n",
      "weighted avg       0.76      0.76      0.76      3170\n",
      "\n",
      "[[1225  360]\n",
      " [ 399 1186]]\n",
      "No of decision tree: 52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.78      0.76      1585\n",
      "           1       0.77      0.74      0.76      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.76      0.76      0.76      3170\n",
      "weighted avg       0.76      0.76      0.76      3170\n",
      "\n",
      "[[1230  355]\n",
      " [ 408 1177]]\n",
      "No of decision tree: 53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76      1585\n",
      "           1       0.77      0.74      0.75      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.76      0.76      0.76      3170\n",
      "weighted avg       0.76      0.76      0.76      3170\n",
      "\n",
      "[[1228  357]\n",
      " [ 409 1176]]\n",
      "No of decision tree: 54\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.78      0.76      1585\n",
      "           1       0.77      0.75      0.76      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.76      0.76      0.76      3170\n",
      "weighted avg       0.76      0.76      0.76      3170\n",
      "\n",
      "[[1229  356]\n",
      " [ 404 1181]]\n",
      "No of decision tree: 55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.78      0.77      1585\n",
      "           1       0.77      0.75      0.76      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.76      0.76      0.76      3170\n",
      "weighted avg       0.76      0.76      0.76      3170\n",
      "\n",
      "[[1230  355]\n",
      " [ 400 1185]]\n",
      "No of decision tree: 56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.78      0.76      1585\n",
      "           1       0.77      0.74      0.76      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.76      0.76      0.76      3170\n",
      "weighted avg       0.76      0.76      0.76      3170\n",
      "\n",
      "[[1231  354]\n",
      " [ 405 1180]]\n",
      "No of decision tree: 57\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.78      0.76      1585\n",
      "           1       0.77      0.74      0.76      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.76      0.76      0.76      3170\n",
      "weighted avg       0.76      0.76      0.76      3170\n",
      "\n",
      "[[1233  352]\n",
      " [ 407 1178]]\n",
      "No of decision tree: 58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.78      0.77      1585\n",
      "           1       0.77      0.74      0.76      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.76      0.76      0.76      3170\n",
      "weighted avg       0.76      0.76      0.76      3170\n",
      "\n",
      "[[1235  350]\n",
      " [ 407 1178]]\n",
      "No of decision tree: 59\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.78      0.76      1585\n",
      "           1       0.77      0.74      0.75      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.76      0.76      0.76      3170\n",
      "weighted avg       0.76      0.76      0.76      3170\n",
      "\n",
      "[[1238  347]\n",
      " [ 415 1170]]\n",
      "No of decision tree: 60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.78      0.77      1585\n",
      "           1       0.77      0.74      0.76      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.76      0.76      0.76      3170\n",
      "weighted avg       0.76      0.76      0.76      3170\n",
      "\n",
      "[[1238  347]\n",
      " [ 411 1174]]\n",
      "No of decision tree: 61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.78      0.76      1585\n",
      "           1       0.77      0.74      0.75      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.76      0.76      0.76      3170\n",
      "weighted avg       0.76      0.76      0.76      3170\n",
      "\n",
      "[[1239  346]\n",
      " [ 416 1169]]\n",
      "No of decision tree: 62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.78      0.76      1585\n",
      "           1       0.77      0.73      0.75      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.76      0.76      0.76      3170\n",
      "weighted avg       0.76      0.76      0.76      3170\n",
      "\n",
      "[[1244  341]\n",
      " [ 428 1157]]\n",
      "No of decision tree: 63\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.79      0.76      1585\n",
      "           1       0.77      0.73      0.75      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.76      0.76      0.76      3170\n",
      "weighted avg       0.76      0.76      0.76      3170\n",
      "\n",
      "[[1247  338]\n",
      " [ 430 1155]]\n",
      "No of decision tree: 64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.79      0.76      1585\n",
      "           1       0.77      0.72      0.75      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.76      0.76      0.75      3170\n",
      "weighted avg       0.76      0.76      0.75      3170\n",
      "\n",
      "[[1248  337]\n",
      " [ 439 1146]]\n",
      "No of decision tree: 65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.79      0.76      1585\n",
      "           1       0.77      0.73      0.75      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.76      0.76      0.76      3170\n",
      "weighted avg       0.76      0.76      0.76      3170\n",
      "\n",
      "[[1246  339]\n",
      " [ 430 1155]]\n",
      "No of decision tree: 66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.79      0.76      1585\n",
      "           1       0.77      0.72      0.75      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.76      0.75      0.75      3170\n",
      "weighted avg       0.76      0.75      0.75      3170\n",
      "\n",
      "[[1246  339]\n",
      " [ 440 1145]]\n",
      "No of decision tree: 67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.79      0.76      1585\n",
      "           1       0.77      0.72      0.74      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.75      0.75      0.75      3170\n",
      "weighted avg       0.75      0.75      0.75      3170\n",
      "\n",
      "[[1249  336]\n",
      " [ 448 1137]]\n",
      "No of decision tree: 68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.79      0.76      1585\n",
      "           1       0.77      0.72      0.74      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.75      0.75      0.75      3170\n",
      "weighted avg       0.75      0.75      0.75      3170\n",
      "\n",
      "[[1249  336]\n",
      " [ 450 1135]]\n",
      "No of decision tree: 69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.79      0.76      1585\n",
      "           1       0.77      0.72      0.74      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.75      0.75      0.75      3170\n",
      "weighted avg       0.75      0.75      0.75      3170\n",
      "\n",
      "[[1248  337]\n",
      " [ 447 1138]]\n",
      "No of decision tree: 70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.79      0.76      1585\n",
      "           1       0.77      0.71      0.74      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.75      0.75      0.75      3170\n",
      "weighted avg       0.75      0.75      0.75      3170\n",
      "\n",
      "[[1250  335]\n",
      " [ 459 1126]]\n",
      "No of decision tree: 71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.79      0.76      1585\n",
      "           1       0.77      0.71      0.74      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.75      0.75      0.75      3170\n",
      "weighted avg       0.75      0.75      0.75      3170\n",
      "\n",
      "[[1251  334]\n",
      " [ 459 1126]]\n",
      "No of decision tree: 72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.79      0.76      1585\n",
      "           1       0.77      0.71      0.74      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.75      0.75      0.75      3170\n",
      "weighted avg       0.75      0.75      0.75      3170\n",
      "\n",
      "[[1249  336]\n",
      " [ 460 1125]]\n",
      "No of decision tree: 73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.79      0.76      1585\n",
      "           1       0.77      0.71      0.74      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.75      0.75      0.75      3170\n",
      "weighted avg       0.75      0.75      0.75      3170\n",
      "\n",
      "[[1254  331]\n",
      " [ 458 1127]]\n",
      "No of decision tree: 74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.79      0.76      1585\n",
      "           1       0.77      0.71      0.74      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.75      0.75      0.75      3170\n",
      "weighted avg       0.75      0.75      0.75      3170\n",
      "\n",
      "[[1253  332]\n",
      " [ 458 1127]]\n",
      "No of decision tree: 75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.79      0.76      1585\n",
      "           1       0.77      0.71      0.74      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.75      0.75      0.75      3170\n",
      "weighted avg       0.75      0.75      0.75      3170\n",
      "\n",
      "[[1253  332]\n",
      " [ 466 1119]]\n",
      "No of decision tree: 76\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.79      0.76      1585\n",
      "           1       0.77      0.70      0.74      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.75      0.75      0.75      3170\n",
      "weighted avg       0.75      0.75      0.75      3170\n",
      "\n",
      "[[1253  332]\n",
      " [ 469 1116]]\n",
      "No of decision tree: 77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.79      0.76      1585\n",
      "           1       0.77      0.70      0.74      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.75      0.75      0.75      3170\n",
      "weighted avg       0.75      0.75      0.75      3170\n",
      "\n",
      "[[1252  333]\n",
      " [ 469 1116]]\n",
      "No of decision tree: 78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.79      0.76      1585\n",
      "           1       0.77      0.71      0.74      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.75      0.75      0.75      3170\n",
      "weighted avg       0.75      0.75      0.75      3170\n",
      "\n",
      "[[1251  334]\n",
      " [ 466 1119]]\n",
      "No of decision tree: 79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.79      0.76      1585\n",
      "           1       0.77      0.70      0.74      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.75      0.75      0.75      3170\n",
      "weighted avg       0.75      0.75      0.75      3170\n",
      "\n",
      "[[1255  330]\n",
      " [ 469 1116]]\n",
      "No of decision tree: 80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.79      0.76      1585\n",
      "           1       0.77      0.71      0.74      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.75      0.75      0.75      3170\n",
      "weighted avg       0.75      0.75      0.75      3170\n",
      "\n",
      "[[1252  333]\n",
      " [ 467 1118]]\n",
      "No of decision tree: 81\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.79      0.76      1585\n",
      "           1       0.77      0.71      0.74      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.75      0.75      0.75      3170\n",
      "weighted avg       0.75      0.75      0.75      3170\n",
      "\n",
      "[[1254  331]\n",
      " [ 467 1118]]\n",
      "No of decision tree: 82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.79      0.76      1585\n",
      "           1       0.77      0.71      0.74      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.75      0.75      0.75      3170\n",
      "weighted avg       0.75      0.75      0.75      3170\n",
      "\n",
      "[[1256  329]\n",
      " [ 467 1118]]\n",
      "No of decision tree: 83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.79      0.76      1585\n",
      "           1       0.77      0.71      0.74      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.75      0.75      0.75      3170\n",
      "weighted avg       0.75      0.75      0.75      3170\n",
      "\n",
      "[[1256  329]\n",
      " [ 467 1118]]\n",
      "No of decision tree: 84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.79      0.76      1585\n",
      "           1       0.77      0.71      0.74      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.75      0.75      0.75      3170\n",
      "weighted avg       0.75      0.75      0.75      3170\n",
      "\n",
      "[[1256  329]\n",
      " [ 466 1119]]\n",
      "No of decision tree: 85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.79      0.76      1585\n",
      "           1       0.77      0.70      0.74      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.75      0.75      0.75      3170\n",
      "weighted avg       0.75      0.75      0.75      3170\n",
      "\n",
      "[[1257  328]\n",
      " [ 468 1117]]\n",
      "No of decision tree: 86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.79      0.76      1585\n",
      "           1       0.77      0.71      0.74      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.75      0.75      0.75      3170\n",
      "weighted avg       0.75      0.75      0.75      3170\n",
      "\n",
      "[[1255  330]\n",
      " [ 461 1124]]\n",
      "No of decision tree: 87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.79      0.76      1585\n",
      "           1       0.77      0.71      0.74      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.75      0.75      0.75      3170\n",
      "weighted avg       0.75      0.75      0.75      3170\n",
      "\n",
      "[[1255  330]\n",
      " [ 460 1125]]\n",
      "No of decision tree: 88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.79      0.76      1585\n",
      "           1       0.77      0.71      0.74      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.75      0.75      0.75      3170\n",
      "weighted avg       0.75      0.75      0.75      3170\n",
      "\n",
      "[[1253  332]\n",
      " [ 460 1125]]\n",
      "No of decision tree: 89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.79      0.76      1585\n",
      "           1       0.77      0.71      0.74      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.75      0.75      0.75      3170\n",
      "weighted avg       0.75      0.75      0.75      3170\n",
      "\n",
      "[[1256  329]\n",
      " [ 460 1125]]\n",
      "No of decision tree: 90\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.79      0.76      1585\n",
      "           1       0.77      0.71      0.74      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.75      0.75      0.75      3170\n",
      "weighted avg       0.75      0.75      0.75      3170\n",
      "\n",
      "[[1255  330]\n",
      " [ 460 1125]]\n",
      "No of decision tree: 91\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.79      0.76      1585\n",
      "           1       0.77      0.71      0.74      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.75      0.75      0.75      3170\n",
      "weighted avg       0.75      0.75      0.75      3170\n",
      "\n",
      "[[1256  329]\n",
      " [ 458 1127]]\n",
      "No of decision tree: 92\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.79      0.76      1585\n",
      "           1       0.77      0.71      0.74      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.75      0.75      0.75      3170\n",
      "weighted avg       0.75      0.75      0.75      3170\n",
      "\n",
      "[[1255  330]\n",
      " [ 458 1127]]\n",
      "No of decision tree: 93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.79      0.76      1585\n",
      "           1       0.77      0.71      0.74      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.75      0.75      0.75      3170\n",
      "weighted avg       0.75      0.75      0.75      3170\n",
      "\n",
      "[[1258  327]\n",
      " [ 465 1120]]\n",
      "No of decision tree: 94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.79      0.76      1585\n",
      "           1       0.77      0.71      0.74      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.75      0.75      0.75      3170\n",
      "weighted avg       0.75      0.75      0.75      3170\n",
      "\n",
      "[[1258  327]\n",
      " [ 461 1124]]\n",
      "No of decision tree: 95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.79      0.76      1585\n",
      "           1       0.77      0.70      0.74      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.75      0.75      0.75      3170\n",
      "weighted avg       0.75      0.75      0.75      3170\n",
      "\n",
      "[[1259  326]\n",
      " [ 468 1117]]\n",
      "No of decision tree: 96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.80      0.76      1585\n",
      "           1       0.78      0.70      0.74      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.75      0.75      0.75      3170\n",
      "weighted avg       0.75      0.75      0.75      3170\n",
      "\n",
      "[[1262  323]\n",
      " [ 468 1117]]\n",
      "No of decision tree: 97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.80      0.76      1585\n",
      "           1       0.78      0.70      0.74      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.75      0.75      0.75      3170\n",
      "weighted avg       0.75      0.75      0.75      3170\n",
      "\n",
      "[[1261  324]\n",
      " [ 468 1117]]\n",
      "No of decision tree: 98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.80      0.76      1585\n",
      "           1       0.78      0.71      0.74      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.75      0.75      0.75      3170\n",
      "weighted avg       0.75      0.75      0.75      3170\n",
      "\n",
      "[[1262  323]\n",
      " [ 462 1123]]\n",
      "No of decision tree: 99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.80      0.76      1585\n",
      "           1       0.78      0.71      0.74      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.75      0.75      0.75      3170\n",
      "weighted avg       0.75      0.75      0.75      3170\n",
      "\n",
      "[[1262  323]\n",
      " [ 466 1119]]\n",
      "No of decision tree: 100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.79      0.76      1585\n",
      "           1       0.77      0.71      0.74      1585\n",
      "\n",
      "    accuracy                           0.75      3170\n",
      "   macro avg       0.75      0.75      0.75      3170\n",
      "weighted avg       0.75      0.75      0.75      3170\n",
      "\n",
      "[[1260  325]\n",
      " [ 466 1119]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10,101):\n",
    "    xgb=XGBClassifier(n_estimators=i,random_state=1)\n",
    "    print('No of decision tree:',i)\n",
    "    xgb=create_model(xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d2c4e169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.75      0.77      1585\n",
      "           1       0.76      0.80      0.78      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.78      0.78      0.78      3170\n",
      "weighted avg       0.78      0.78      0.78      3170\n",
      "\n",
      "[[1193  392]\n",
      " [ 315 1270]]\n"
     ]
    }
   ],
   "source": [
    "#XtremeGradientBoostClassifier\n",
    "#Number of Decision Tree=12\n",
    "xgb=XGBClassifier(n_estimators=12,random_state=1)\n",
    "xgb=create_model(xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "638587cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.72      0.77      1585\n",
      "           1       0.75      0.85      0.80      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.79      0.78      0.78      3170\n",
      "weighted avg       0.79      0.78      0.78      3170\n",
      "\n",
      "[[1142  443]\n",
      " [ 244 1341]]\n"
     ]
    }
   ],
   "source": [
    "#Apply Support Vector Machine algorithm with hard margin\n",
    "from sklearn.svm import LinearSVC\n",
    "svc=LinearSVC(random_state=1)\n",
    "svc=create_model(svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "93dada4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.72      0.77      1585\n",
      "           1       0.75      0.85      0.80      1585\n",
      "\n",
      "    accuracy                           0.78      3170\n",
      "   macro avg       0.79      0.78      0.78      3170\n",
      "weighted avg       0.79      0.78      0.78      3170\n",
      "\n",
      "[[1142  443]\n",
      " [ 244 1341]]\n"
     ]
    }
   ],
   "source": [
    "#Apply Support Vector Machine algorithm with soft margin\n",
    "svc1=LinearSVC(random_state=1,C=0.9)\n",
    "svc1=create_model(svc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "679be210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.73      0.75      1585\n",
      "           1       0.74      0.80      0.77      1585\n",
      "\n",
      "    accuracy                           0.76      3170\n",
      "   macro avg       0.76      0.76      0.76      3170\n",
      "weighted avg       0.76      0.76      0.76      3170\n",
      "\n",
      "[[1151  434]\n",
      " [ 320 1265]]\n"
     ]
    }
   ],
   "source": [
    "#No improvent in recall score, means data is non linear \n",
    "#Apply Support Vector Machine algorithm for non linear data with polynomial kernel function\n",
    "from sklearn.svm import SVC\n",
    "poly_svc=SVC(random_state=1,kernel='poly')\n",
    "poly_svc=create_model(poly_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "af376450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.76      1585\n",
      "           1       0.75      0.79      0.77      1585\n",
      "\n",
      "    accuracy                           0.77      3170\n",
      "   macro avg       0.77      0.77      0.77      3170\n",
      "weighted avg       0.77      0.77      0.77      3170\n",
      "\n",
      "[[1178  407]\n",
      " [ 337 1248]]\n"
     ]
    }
   ],
   "source": [
    "#Apply Support Vector Machine algorithm for non linear data with radial basis kernel function\n",
    "r_svc=SVC(random_state=1,kernel='rbf')\n",
    "r_svc=create_model(r_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "570adcae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.66      0.70      1585\n",
      "           1       0.69      0.75      0.72      1585\n",
      "\n",
      "    accuracy                           0.71      3170\n",
      "   macro avg       0.71      0.71      0.71      3170\n",
      "weighted avg       0.71      0.71      0.71      3170\n",
      "\n",
      "[[1053  532]\n",
      " [ 390 1195]]\n"
     ]
    }
   ],
   "source": [
    "#Apply KNN algorithm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knc=KNeighborsClassifier(n_neighbors=5,metric='minkowski',p=2)\n",
    "knc=create_model(knc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5cd0595c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Recall 0</th>\n",
       "      <th>Recall 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ADA</td>\n",
       "      <td>68</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GBC</td>\n",
       "      <td>69</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RFC_max</td>\n",
       "      <td>71</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DTC_G_max</td>\n",
       "      <td>69</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DTC_G_min</td>\n",
       "      <td>71</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DTC_E_max</td>\n",
       "      <td>70</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RFC_min</td>\n",
       "      <td>74</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logostic Regression</td>\n",
       "      <td>74</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DTC_G_min</td>\n",
       "      <td>74</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XGB</td>\n",
       "      <td>76</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVC_poly</td>\n",
       "      <td>73</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVC_r</td>\n",
       "      <td>75</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KNN</td>\n",
       "      <td>66</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Algorithm  Recall 0  Recall 1\n",
       "7                   ADA        68        85\n",
       "8                   GBC        69        85\n",
       "5               RFC_max        71        83\n",
       "1             DTC_G_max        69        82\n",
       "2             DTC_G_min        71        81\n",
       "3             DTC_E_max        70        81\n",
       "6               RFC_min        74        81\n",
       "0   Logostic Regression        74        80\n",
       "4             DTC_G_min        74        80\n",
       "9                   XGB        76        78\n",
       "10             SVC_poly        73        78\n",
       "11                SVC_r        75        77\n",
       "12                  KNN        66        75"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict={'Algorithm':['Logostic Regression','DTC_G_max','DTC_G_min','DTC_E_max','DTC_G_min','RFC_max','RFC_min','ADA','GBC','XGB','SVC_poly','SVC_r','KNN'],\n",
    "     'Recall 0':[74,69,71,70,74,71,74,68,69,76,73,75,66],\n",
    "     'Recall 1':[80,82,81,81,80,83,81,85,85,78,78,77,75]}\n",
    "df1=pd.DataFrame(dict)\n",
    "df1.sort_values('Recall 1',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b94761",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff0ed95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb6cb42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
